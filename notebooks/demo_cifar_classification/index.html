
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="../../api/singular_values/">
      
      
        <link rel="next" href="../../CONTRIBUTING/">
      
      
      <link rel="icon" href="../../assets/banner.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.3">
    
    
      
        <title>Demo 1: Certifiable robustness with 1-Lipschitz networks - orthogonium</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.d7758b05.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../assets/_mkdocstrings.css">
    
      <link rel="stylesheet" href="../../css/custom.css">
    
      <link rel="stylesheet" href="../../css/ansi-colours.css">
    
      <link rel="stylesheet" href="../../css/jupyter-cells.css">
    
      <link rel="stylesheet" href="../../css/pandas-dataframe.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="dark" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#training-a-1-lipschitz-constrained-network-on-cifar10-with-orthogonium" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="orthogonium" class="md-header__button md-logo" aria-label="orthogonium" data-md-component="logo">
      
  <img src="../../assets/banner.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            orthogonium
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Demo 1: Certifiable robustness with 1-Lipschitz networks
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="dark" data-md-color-accent="indigo"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 6H7c-3.31 0-6 2.69-6 6s2.69 6 6 6h10c3.31 0 6-2.69 6-6s-2.69-6-6-6m0 10H7c-2.21 0-4-1.79-4-4s1.79-4 4-4h10c2.21 0 4 1.79 4 4s-1.79 4-4 4M7 9c-1.66 0-3 1.34-3 3s1.34 3 3 3 3-1.34 3-3-1.34-3-3-3"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h10a5 5 0 0 0 5-5 5 5 0 0 0-5-5m0 8a3 3 0 0 1-3-3 3 3 0 0 1 3-3 3 3 0 0 1 3 3 3 3 0 0 1-3 3"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/thib-s/orthogonium" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
  </div>
  <div class="md-source__repository">
    thib-s/orthogonium
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="orthogonium" class="md-nav__button md-logo" aria-label="orthogonium" data-md-component="logo">
      
  <img src="../../assets/banner.png" alt="logo">

    </a>
    orthogonium
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/thib-s/orthogonium" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
  </div>
  <div class="md-source__repository">
    thib-s/orthogonium
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    API Reference
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            API Reference
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../api/conv/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    convolutions
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../api/linear/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    linear layers
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../api/reparametrizers/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    reparametrizers
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../api/activations/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    activations
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../api/losses/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    losses
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../api/singular_values/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    singular values
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" checked>
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Tutorials
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            Tutorials
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    Demo 1: Certifiable robustness with 1-Lipschitz networks
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    Demo 1: Certifiable robustness with 1-Lipschitz networks
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#lipschitz-constrained-networks-and-certifiable-robustness" class="md-nav__link">
    <span class="md-ellipsis">
      Lipschitz-Constrained Networks and Certifiable Robustness
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#training-settings" class="md-nav__link">
    <span class="md-ellipsis">
      Training Settings
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#training-settings-performance" class="md-nav__link">
    <span class="md-ellipsis">
      Training Settings Performance
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#data-module-cifar10" class="md-nav__link">
    <span class="md-ellipsis">
      Data Module: CIFAR10
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classification-model-module" class="md-nav__link">
    <span class="md-ellipsis">
      Classification Model Module
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#training-routine" class="md-nav__link">
    <span class="md-ellipsis">
      Training Routine
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#next-steps" class="md-nav__link">
    <span class="md-ellipsis">
      Next Steps
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../CONTRIBUTING/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Contributing
    
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#lipschitz-constrained-networks-and-certifiable-robustness" class="md-nav__link">
    <span class="md-ellipsis">
      Lipschitz-Constrained Networks and Certifiable Robustness
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#training-settings" class="md-nav__link">
    <span class="md-ellipsis">
      Training Settings
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#training-settings-performance" class="md-nav__link">
    <span class="md-ellipsis">
      Training Settings Performance
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#data-module-cifar10" class="md-nav__link">
    <span class="md-ellipsis">
      Data Module: CIFAR10
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classification-model-module" class="md-nav__link">
    <span class="md-ellipsis">
      Classification Model Module
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#training-routine" class="md-nav__link">
    <span class="md-ellipsis">
      Training Routine
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#next-steps" class="md-nav__link">
    <span class="md-ellipsis">
      Next Steps
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


  
  


<h1 id="training-a-1-lipschitz-constrained-network-on-cifar10-with-orthogonium">Training a 1-Lipschitz constrained network on CIFAR10 with Orthogonium<a class="headerlink" href="#training-a-1-lipschitz-constrained-network-on-cifar10-with-orthogonium" title="Permanent link">&para;</a></h1>
<h2 id="lipschitz-constrained-networks-and-certifiable-robustness">Lipschitz-Constrained Networks and Certifiable Robustness<a class="headerlink" href="#lipschitz-constrained-networks-and-certifiable-robustness" title="Permanent link">&para;</a></h2>
<p><strong>What is a Lipschitz Network?</strong>
A <em>Lipschitz network</em> is a neural network in which each layer is constrained to be a 1-Lipschitz function. This means that small changes in the input lead to only small changes in the output, ensuring controlled sensitivity throughout the network. The overall Lipschitz constant of the network is usually estimated as the product of the Lipschitz constants of its individual layers. However, this bound is often loose and difficult to compute exactly.</p>
<p><strong>How to Build Lipschitz Networks?</strong>
To construct such networks:
- <strong>Orthogonal Layers:</strong> Use layers that enforce orthogonality constraints (e.g., Adaptive OrthoConvolutions). These layers are designed to strictly represent 1-Lipschitz functions.
- <strong>Special Activations:</strong> Incorporate activations like <strong>MaxMin</strong> which, when combined with orthogonal layers, help in obtaining a tight estimation of the network's Lipschitz constant.
- <strong>Reparametrization Techniques:</strong> Methods such as AOC (Adaptive OrthoConvolutions) ensure that each layer adheres to the 1-Lipschitz constraint, making the overall bound much tighter compared to a simple product of individual bounds.</p>
<p><strong>Certifiable Robustness</strong>
Certifiable robustness provides a guarantee on the minimal perturbation needed to alter the network's prediction, independent of any specific adversarial attack. For a 1-Lipschitz classification function $ f $ with $ f(x)<em _neq="\neq" i="i" l="l">l $ representing the logit for the true class and $ f(x)_i $ for any other class, a robustness certificate in the $ L_2 $ norm is given by:
$$
\epsilon \geq \frac{f(x)_l - \max</em>
$$
This means that as long as the perturbation remains below $ \epsilon $, the classification will not change. This certificate is:
- } f(x)_i}{\sqrt{2}<strong>Independent of Attacks:</strong> It does not rely on any particular adversarial attack method, ensuring that the guarantee remains valid even as new attack strategies emerge.
- <strong>Computationally Efficient:</strong> The certificate can be computed cheaply and even integrated as a loss term during training, leading to models that are robust by design.</p>
<p><strong>Applications and Benefits</strong>
Lipschitz-constrained networks are not only crucial for certifiable robustness but also have broader applications:
- They are tightly linked with generative models like WGANs and concepts in optimal transport.
- They enable scalable differential privacy and help avoid singularities in models such as diffusion networks.
- They guarantee existence and uniqueness in classification tasks, making them appealing for reliable machine learning.</p>
<p>In summary, by combining orthogonal layers with appropriate activations and reparametrization techniques, one can build Lipschitz networks that not only deliver competitive performance but also offer provable robustness guarantees.</p>
<div class="highlight"><pre><span></span><code># !pip install orthogonium lightning rich schedulefree
</code></pre></div>
<div class="highlight"><pre><span></span><code>import math
import os

import schedulefree
import torch
import torch.utils.data
import torchmetrics
from lightning.pytorch import callbacks as pl_callbacks
from lightning.pytorch import Trainer
from lightning.pytorch import LightningModule, LightningDataModule
from torchinfo import summary
# from lightning.pytorch.loggers import WandbLogger  # Uncomment if using Wandb logging
from torch.nn import AvgPool2d
from torch.utils.data import DataLoader
from torchvision.datasets import CIFAR10
from torchvision.transforms import Compose, Normalize, RandAugment, RandomHorizontalFlip, RandomResizedCrop, ToTensor

from orthogonium.model_factory.classparam import ClassParam
from orthogonium.layers.conv.AOC import AdaptiveOrthoConv2d
from orthogonium.layers.linear import OrthoLinear
from orthogonium.layers.custom_activations import MaxMin
from orthogonium.losses import LossXent, CosineLoss
from orthogonium.losses import VRA
from orthogonium.model_factory.models_factory import StagedCNN, PatchBasedExapandedCNN

# Enable benchmark mode and set matmul precision for performance tuning
torch.backends.cudnn.benchmark = True
torch.set_float32_matmul_precision(&quot;medium&quot;)
</code></pre></div>
<h2 id="training-settings">Training Settings<a class="headerlink" href="#training-settings" title="Permanent link">&para;</a></h2>
<p>You can play with the training settings to explore different configurations and compare their performance. The settings include:</p>
<p><strong>Training settings include:</strong>
- <strong>non_robust:</strong> Cosine Similarity loss training.
- <strong>mildly_robust:</strong> Cross Entropy Loss includes a high margin targeting a VRA of 36/255, resulting in 42% VRA.
- <strong>robust:</strong> Similar to mildly robust, but with settings that push towards 72/255 verified robust accuracy, resulting in 47% VRA.</p>
<blockquote>
<p>Note: The aim here is to show the training flow rather than reach state-of-the-art performance.</p>
</blockquote>
<h2 id="training-settings-performance">Training Settings Performance<a class="headerlink" href="#training-settings-performance" title="Permanent link">&para;</a></h2>
<table>
<thead>
<tr>
<th>Setting</th>
<th>Epochs</th>
<th>Accuracy</th>
<th>Verified Robust Accuracy (VRA)</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>non_robust</strong></td>
<td>60</td>
<td>88.5%</td>
<td>0%</td>
</tr>
<tr>
<td><strong>mildly_robust</strong></td>
<td>150</td>
<td>75%</td>
<td>42%</td>
</tr>
<tr>
<td><strong>robust</strong></td>
<td>150</td>
<td>71%</td>
<td>47%</td>
</tr>
</tbody>
</table>
<p>These configurations are stored in the <code>settings</code> dictionary.</p>
<div class="highlight"><pre><span></span><code>settings = {
    &quot;non_robust&quot;: {
        &quot;loss&quot;: CosineLoss,
        &quot;epochs&quot;: 60,
    },
    &quot;mildly_robust&quot;: {
        &quot;loss&quot;: ClassParam(
            LossXent,
            n_classes=10,
            offset=(math.sqrt(2) / 0.1983) * (36 / 255),  # aiming for 36/255 verified robust accuracy
            temperature=0.125,
        ),
        &quot;epochs&quot;: 150,
    },
    &quot;robust&quot;: {
        &quot;loss&quot;: ClassParam(
            LossXent,
            n_classes=10,
            offset=(math.sqrt(2) / 0.1983) * (72 / 255),  # aiming for 72/255 verified robust accuracy
            temperature=0.25,
        ),
        &quot;epochs&quot;: 150,
    },
}
</code></pre></div>
<h2 id="data-module-cifar10">Data Module: CIFAR10<a class="headerlink" href="#data-module-cifar10" title="Permanent link">&para;</a></h2>
<p>We create a <code>LightningDataModule</code> to load and preprocess the CIFAR10 training and validation datasets.</p>
<p>The training dataloader applies several transforms:
- Random resized cropping
- Random horizontal flip
- Normalization using precomputed mean and standard deviation</p>
<p>The validation dataloader only applies tensor conversion and normalization.</p>
<div class="highlight"><pre><span></span><code>class Cifar10DataModule(LightningDataModule):
    # Dataset configuration
    _BATCH_SIZE = 256
    _NUM_WORKERS = 8  # Number of parallel processes for data loading
    _PREPROCESSING_PARAMS = {
        &quot;img_mean&quot;: (0.41757566, 0.26098573, 0.25888634),
        &quot;img_std&quot;: (0.21938758, 0.1983, 0.19342837),
        &quot;crop_size&quot;: 32,
        &quot;horizontal_flip_prob&quot;: 0.5,
        &quot;random_resized_crop_params&quot;: {
            &quot;scale&quot;: (0.25, 1.0),
            &quot;ratio&quot;: (3.0 / 4.0, 4.0 / 3.0),
        },
    }

    def train_dataloader(self):
        # Define the transformations for training data
        transform = Compose(
            [
                RandomResizedCrop(
                    self._PREPROCESSING_PARAMS[&quot;crop_size&quot;],
                    **self._PREPROCESSING_PARAMS[&quot;random_resized_crop_params&quot;],
                ),
                RandomHorizontalFlip(self._PREPROCESSING_PARAMS[&quot;horizontal_flip_prob&quot;]),
                # Uncomment the following line to use RandAugment
                # RandAugment(**self._PREPROCESSING_PARAMS[&quot;randaug_params&quot;]),
                ToTensor(),
                Normalize(
                    mean=self._PREPROCESSING_PARAMS[&quot;img_mean&quot;],
                    std=self._PREPROCESSING_PARAMS[&quot;img_std&quot;],
                ),
            ]
        )

        train_dataset = CIFAR10(
            root=&quot;./data&quot;,
            train=True,
            download=True,
            transform=transform,
        )

        return DataLoader(
            train_dataset,
            batch_size=self._BATCH_SIZE,
            num_workers=self._NUM_WORKERS,
            prefetch_factor=2,
            shuffle=True,
        )

    def val_dataloader(self):
        # Define the transformations for validation data
        transform = Compose(
            [
                ToTensor(),
                Normalize(
                    mean=self._PREPROCESSING_PARAMS[&quot;img_mean&quot;],
                    std=self._PREPROCESSING_PARAMS[&quot;img_std&quot;],
                ),
            ]
        )

        val_dataset = CIFAR10(
            root=&quot;./data&quot;,
            train=False,
            download=True,
            transform=transform,
        )

        return DataLoader(
            val_dataset,
            batch_size=self._BATCH_SIZE * 4,
            num_workers=self._NUM_WORKERS,
            shuffle=False,
        )
</code></pre></div>
<h2 id="classification-model-module">Classification Model Module<a class="headerlink" href="#classification-model-module" title="Permanent link">&para;</a></h2>
<p>We now define a <code>LightningModule</code> that wraps our CNN model. The network uses the <code>PatchBasedExapandedCNN</code> factory method from <em>orthogonium</em>.</p>
<p>The architecture consists of 4 main parts:
- The stem is a patch extractor: a convolution whose kernel size equals the stride.
- A sequence of residual block: each residual features a learnable factor to ensure its Lipschitzness. In each residual, there is one depthwise convolution, A MaxMin activation, and a pointwise convolution. No pooling is performed in this part of the network.
- A pooling layer: here, we use a depthwise convolution whose kernel size equals the image size. This allows for the localization of features without using a large amount of weight. (this is not mandatory for accurate training but seems to obtain a slightly better accuracy / robustness tradeoff in robust training).
- a Fully connected layer for classification.</p>
<p>All convolutional layers use AOC, allowing the construction of complex Lipschitz-constrained architectures.</p>
<p>Key components include:
- The custom CNN model architecture.
- The loss function (set based on the selected training configuration).
- Training and validation steps that compute and log both accuracy and verified robust accuracy (VRA).
- The <code>configure_optimizers</code> method which sets up the Adam optimizer with schedule-free updates.</p>
<div class="highlight"><pre><span></span><code>class ClassificationLightningModule(LightningModule):
    def __init__(self, num_classes=10, loss=None):
        super().__init__()
        self.num_classes = num_classes
        self.model = PatchBasedExapandedCNN(
            img_shape=(3, 32, 32),
            dim=256,
            depth=12,
            kernel_size=3,
            patch_size=2,
            expand_factor=2,
            groups=None,
            n_classes=10,
            skip=True,
            conv=ClassParam(
                AdaptiveOrthoConv2d,
                bias=False,
                padding=&quot;same&quot;,
                padding_mode=&quot;zeros&quot;,
            ),
            act=ClassParam(MaxMin),
            pool=ClassParam(
                AdaptiveOrthoConv2d,
                in_channels=256,
                out_channels=256,
                groups=128,
                bias=False,
                padding=0,
                kernel_size=16,
                stride=16,
            ),
            lin=ClassParam(OrthoLinear, bias=False),
            norm=None,
        )
        self.criteria = loss() if loss is not None else torch.nn.CrossEntropyLoss()
        self.train_acc = torchmetrics.Accuracy(task=&quot;multiclass&quot;, num_classes=num_classes)
        self.val_acc = torchmetrics.Accuracy(task=&quot;multiclass&quot;, num_classes=num_classes)
        self.train_vra = torchmetrics.MeanMetric()
        self.val_vra = torchmetrics.MeanMetric()

    def forward(self, x):
        return self.model(x)

    def training_step(self, batch, batch_idx):
        self.model.train()
        img, label = batch
        y_hat = self.model(img)
        loss = self.criteria(y_hat, label)
        self.train_acc(y_hat, label)
        self.train_vra(
            VRA(
                y_hat,
                label,
                L=1 / min(Cifar10DataModule._PREPROCESSING_PARAMS[&quot;img_std&quot;]),
                eps=36 / 255,
                last_layer_type=&quot;global&quot;,
            )
        )
        self.log(&quot;loss&quot;, loss, on_epoch=True, on_step=True, prog_bar=True, sync_dist=True)
        self.log(&quot;accuracy&quot;, self.train_acc, on_epoch=True, on_step=True, prog_bar=True, sync_dist=True)
        self.log(&quot;vra&quot;, self.train_vra, on_epoch=True, on_step=True, prog_bar=True, sync_dist=False)
        return loss

    def validation_step(self, batch, batch_idx):
        self.model.eval()
        img, label = batch
        y_hat = self.model(img)
        loss = self.criteria(y_hat, label)
        self.val_acc(y_hat, label)
        self.val_vra(
            VRA(
                y_hat,
                label,
                L=1 / min(Cifar10DataModule._PREPROCESSING_PARAMS[&quot;img_std&quot;]),
                eps=36 / 255,
                last_layer_type=&quot;global&quot;,
            )
        )
        self.log(&quot;val_loss&quot;, loss, on_epoch=True, on_step=False, prog_bar=True, sync_dist=True)
        self.log(&quot;val_accuracy&quot;, self.val_acc, on_epoch=True, on_step=False, prog_bar=True, sync_dist=True)
        self.log(&quot;val_vra&quot;, self.val_vra, on_epoch=True, on_step=False, prog_bar=True, sync_dist=True)
        return loss

    def configure_optimizers(self):
        # Setup the Adam optimizer with schedule-free updates.
        optimizer = schedulefree.AdamWScheduleFree(self.parameters(), lr=5e-3, weight_decay=0)
        optimizer.train()
        self.hparams[&quot;lr&quot;] = optimizer.param_groups[0][&quot;lr&quot;]
        return optimizer
</code></pre></div>
<h2 id="training-routine">Training Routine<a class="headerlink" href="#training-routine" title="Permanent link">&para;</a></h2>
<p>For example, to run a <strong>non robust</strong> training setting, set:</p>
<div class="highlight"><pre><span></span><code><span class="n">train_setting</span> <span class="o">=</span> <span class="s2">&quot;non_robust&quot;</span>


<span class="c1"># Select the training setting manually.</span>
<span class="n">train_setting</span> <span class="o">=</span> <span class="s2">&quot;non_robust&quot;</span>  <span class="c1"># Options: &quot;non_robust&quot;, &quot;mildly_robust&quot;, or &quot;robust&quot;</span>

<span class="c1"># Get the corresponding loss function and number of epochs from the settings.</span>
<span class="n">current_setting</span> <span class="o">=</span> <span class="n">settings</span><span class="p">[</span><span class="n">train_setting</span><span class="p">]</span>

<span class="c1"># Instantiate the classification model and data module.</span>
<span class="n">classification_module</span> <span class="o">=</span> <span class="n">ClassificationLightningModule</span><span class="p">(</span><span class="n">num_classes</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="n">current_setting</span><span class="p">[</span><span class="s2">&quot;loss&quot;</span><span class="p">])</span>
<span class="n">data_module</span> <span class="o">=</span> <span class="n">Cifar10DataModule</span><span class="p">()</span>

<span class="c1"># Optionally, set up a logger or callbacks if needed.</span>
<span class="c1"># For example, if using Wandb:</span>
<span class="c1"># from lightning.pytorch.loggers import WandbLogger</span>
<span class="c1"># wandb_logger = WandbLogger(project=&quot;lipschitz-robust-cifar10&quot;, log_model=True)</span>
<span class="c1"># checkpoint_callback = pl_callbacks.ModelCheckpoint(</span>
<span class="c1">#     monitor=&quot;loss&quot;,</span>
<span class="c1">#     mode=&quot;min&quot;,</span>
<span class="c1">#     save_top_k=1,</span>
<span class="c1">#     save_last=True,</span>
<span class="c1">#     dirpath=f&quot;./checkpoints/{wandb_logger.experiment.dir}&quot;,</span>
<span class="c1"># )</span>

<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span>
    <span class="n">accelerator</span><span class="o">=</span><span class="s2">&quot;gpu&quot;</span><span class="p">,</span>
    <span class="n">devices</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>  <span class="c1"># Use 1 GPU set to -1 for all GPUs</span>
    <span class="n">num_nodes</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>  <span class="c1"># Number of nodes</span>
    <span class="c1"># strategy=&quot;ddp_spawn&quot;,         # Distributed strategy</span>
    <span class="n">precision</span><span class="o">=</span><span class="s2">&quot;bf16-mixed&quot;</span><span class="p">,</span>  <span class="c1"># Mixed precision training</span>
    <span class="n">max_epochs</span><span class="o">=</span><span class="n">current_setting</span><span class="p">[</span><span class="s2">&quot;epochs&quot;</span><span class="p">],</span>
    <span class="n">enable_model_summary</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="c1"># logger=[wandb_logger],  # Uncomment to enable Wandb logging</span>
    <span class="n">logger</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">enable_progress_bar</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span>
        <span class="c1"># You can add callbacks here, e.g.:</span>
        <span class="c1"># pl_callbacks.LearningRateFinder(max_lr=0.05),</span>
        <span class="c1"># checkpoint_callback,</span>
    <span class="p">],</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">summary</span><span class="p">(</span><span class="n">classification_module</span><span class="p">,</span> <span class="n">input_size</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)))</span>
<span class="c1"># Start training</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">classification_module</span><span class="p">,</span> <span class="n">data_module</span><span class="p">)</span>

<span class="n">Optionally</span><span class="p">,</span> <span class="n">you</span> <span class="n">can</span> <span class="n">save</span> <span class="n">the</span> <span class="n">trained</span> <span class="n">model</span> <span class="n">afterwards</span><span class="p">:</span>
<span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">classification_module</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="s2">&quot;single_stage.pth&quot;</span><span class="p">)</span>
</code></pre></div>
<p><div class="highlight"><pre><span></span><code>    Using bfloat16 Automatic Mixed Precision (AMP)
    GPU available: True (cuda), used: True
    TPU available: False, using: 0 TPU cores
    HPU available: False, using: 0 HPUs
    /mnt/deel/data/thibaut.boissin/envs/ortho/lib/python3.12/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /home/thibaut.boissin/projects/orthogonium/scripts/pareto/checkpoints exists and is not empty.
    LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]


    ==================================================================================================================================
    Layer (type:depth-idx)                                                           Output Shape              Param #
    ==================================================================================================================================
    ClassificationLightningModule                                                    [1, 10]                   --
    ├─Sequential: 1-1                                                                [1, 10]                   --
    │    └─ParametrizedRKOConv2d: 2-1                                                [1, 256, 16, 16]          --
    │    │    └─ModuleDict: 3-1                                                      --                        3,340
    │    └─AdditiveResidual: 2-2                                                     [1, 256, 16, 16]          1
    │    │    └─Sequential: 3-2                                                      [1, 256, 16, 16]          142,592
    │    └─AdditiveResidual: 2-3                                                     [1, 256, 16, 16]          1
    │    │    └─Sequential: 3-3                                                      [1, 256, 16, 16]          142,592
    │    └─AdditiveResidual: 2-4                                                     [1, 256, 16, 16]          1
    │    │    └─Sequential: 3-4                                                      [1, 256, 16, 16]          142,592
    │    └─AdditiveResidual: 2-5                                                     [1, 256, 16, 16]          1
    │    │    └─Sequential: 3-5                                                      [1, 256, 16, 16]          142,592
    │    └─AdditiveResidual: 2-6                                                     [1, 256, 16, 16]          1
    │    │    └─Sequential: 3-6                                                      [1, 256, 16, 16]          142,592
    │    └─AdditiveResidual: 2-7                                                     [1, 256, 16, 16]          1
    │    │    └─Sequential: 3-7                                                      [1, 256, 16, 16]          142,592
    │    └─AdditiveResidual: 2-8                                                     [1, 256, 16, 16]          1
    │    │    └─Sequential: 3-8                                                      [1, 256, 16, 16]          142,592
    │    └─AdditiveResidual: 2-9                                                     [1, 256, 16, 16]          1
    │    │    └─Sequential: 3-9                                                      [1, 256, 16, 16]          142,592
    │    └─AdditiveResidual: 2-10                                                    [1, 256, 16, 16]          1
    │    │    └─Sequential: 3-10                                                     [1, 256, 16, 16]          142,592
    │    └─AdditiveResidual: 2-11                                                    [1, 256, 16, 16]          1
    │    │    └─Sequential: 3-11                                                     [1, 256, 16, 16]          142,592
    │    └─AdditiveResidual: 2-12                                                    [1, 256, 16, 16]          1
    │    │    └─Sequential: 3-12                                                     [1, 256, 16, 16]          142,592
    │    └─AdditiveResidual: 2-13                                                    [1, 256, 16, 16]          1
    │    │    └─Sequential: 3-13                                                     [1, 256, 16, 16]          142,592
    │    └─ParametrizedRKOConv2d: 2-14                                               [1, 256, 1, 1]            --
    │    │    └─ModuleDict: 3-14                                                     --                        196,864
    │    └─Flatten: 2-15                                                             [1, 256]                  --
    │    └─MaxMin: 2-16                                                              [1, 256]                  --
    │    └─ParametrizedOrthoLinear: 2-17                                             [1, 10]                   --
    │    │    └─ModuleDict: 3-15                                                     --                        2,826
    ==================================================================================================================================
    Total params: 1,914,146
    Trainable params: 1,783,308
    Non-trainable params: 130,838
    Total mult-adds (Units.MEGABYTES): 0
    ==================================================================================================================================
    Input size (MB): 0.01
    Forward/backward pass size (MB): 0.00
    Params size (MB): 0.00
    Estimated Total Size (MB): 0.01
    ==================================================================================================================================
    Files already downloaded and verified
    Files already downloaded and verified


    `Trainer.fit` stopped: `max_epochs=60` reached.
</code></pre></div>
trainer.validate(classification_module, datamodule=data_module)
<div class="highlight"><pre><span></span><code>    LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]


    Files already downloaded and verified



┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃      Validate metric      ┃       DataLoader 0        ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│       val_accuracy        │    0.8831999897956848     │
│         val_loss          │    -0.8909505605697632    │
│          val_vra          │            0.0            │
└───────────────────────────┴───────────────────────────┘






    [{&#39;val_loss&#39;: -0.8909505605697632,
      &#39;val_accuracy&#39;: 0.8831999897956848,
      &#39;val_vra&#39;: 0.0}]
</code></pre></div></p>
<h2 id="next-steps">Next Steps<a class="headerlink" href="#next-steps" title="Permanent link">&para;</a></h2>
<ul>
<li><strong>Model Evaluation:</strong> You can add a new cell to perform model evaluation or predictions.</li>
<li><strong>Logging and Checkpoints:</strong> To enable model logging or checkpoint saving, uncomment the corresponding lines and configure as needed.</li>
<li><strong>Experiment with Settings:</strong> Change the <code>train_setting</code> variable to <code>"mildly_robust"</code> or <code>"robust"</code> to experiment with other training configurations.</li>
</ul>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../..", "features": [], "search": "../../assets/javascripts/workers/search.f8cc74c7.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../assets/javascripts/bundle.f1b6f286.min.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
        <script src="../../js/custom.js"></script>
      
    
  </body>
</html>