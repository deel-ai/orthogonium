{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Training a 1-Lipschitz constrained network on CIFAR10 with Orthogonium\n",
    "\n",
    "## Lipschitz-Constrained Networks and Certifiable Robustness\n",
    "\n",
    "**What is a Lipschitz Network?**\n",
    "A *Lipschitz network* is a neural network in which each layer is constrained to be a 1-Lipschitz function. This means that small changes in the input lead to only small changes in the output, ensuring controlled sensitivity throughout the network. The overall Lipschitz constant of the network is usually estimated as the product of the Lipschitz constants of its individual layers. However, this bound is often loose and difficult to compute exactly.\n",
    "\n",
    "**How to Build Lipschitz Networks?**\n",
    "To construct such networks:\n",
    "- **Orthogonal Layers:** Use layers that enforce orthogonality constraints (e.g., Adaptive OrthoConvolutions). These layers are designed to strictly represent 1-Lipschitz functions.\n",
    "- **Special Activations:** Incorporate activations like **MaxMin** which, when combined with orthogonal layers, help in obtaining a tight estimation of the network's Lipschitz constant.\n",
    "- **Reparametrization Techniques:** Methods such as AOC (Adaptive OrthoConvolutions) ensure that each layer adheres to the 1-Lipschitz constraint, making the overall bound much tighter compared to a simple product of individual bounds.\n",
    "\n",
    "**Certifiable Robustness**\n",
    "Certifiable robustness provides a guarantee on the minimal perturbation needed to alter the network's prediction, independent of any specific adversarial attack. For a 1-Lipschitz classification function \\( f \\) with \\( f(x)_l \\) representing the logit for the true class and \\( f(x)_i \\) for any other class, a robustness certificate in the \\( L_2 \\) norm is given by:\n",
    "\\[\n",
    "\\epsilon \\geq \\frac{f(x)_l - \\max_{i \\neq l} f(x)_i}{\\sqrt{2}}\n",
    "\\]\n",
    "This means that as long as the perturbation remains below \\( \\epsilon \\), the classification will not change. This certificate is:\n",
    "- **Independent of Attacks:** It does not rely on any particular adversarial attack method, ensuring that the guarantee remains valid even as new attack strategies emerge.\n",
    "- **Computationally Efficient:** The certificate can be computed cheaply and even integrated as a loss term during training, leading to models that are robust by design.\n",
    "\n",
    "**Applications and Benefits**\n",
    "Lipschitz-constrained networks are not only crucial for certifiable robustness but also have broader applications:\n",
    "- They are tightly linked with generative models like WGANs and concepts in optimal transport.\n",
    "- They enable scalable differential privacy and help avoid singularities in models such as diffusion networks.\n",
    "- They guarantee existence and uniqueness in classification tasks, making them appealing for reliable machine learning.\n",
    "\n",
    "In summary, by combining orthogonal layers with appropriate activations and reparametrization techniques, one can build Lipschitz networks that not only deliver competitive performance but also offer provable robustness guarantees.\n"
   ],
   "id": "430c3d772b2f2bb0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import math\n",
    "import os\n",
    "\n",
    "import schedulefree\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torchmetrics\n",
    "from lightning.pytorch import callbacks as pl_callbacks\n",
    "from lightning.pytorch import Trainer\n",
    "from lightning.pytorch import LightningModule, LightningDataModule\n",
    "# from lightning.pytorch.loggers import WandbLogger  # Uncomment if using Wandb logging\n",
    "from torch.nn import AvgPool2d\n",
    "from torch.utils.data import DataLoader\n",
    "from torchinfo import summary\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.transforms import Compose, Normalize, RandAugment, RandomHorizontalFlip, RandomResizedCrop, ToTensor\n",
    "\n",
    "from orthogonium.model_factory.classparam import ClassParam\n",
    "from orthogonium.layers.conv.AOC import AdaptiveOrthoConv2d\n",
    "from orthogonium.layers.linear import OrthoLinear\n",
    "from orthogonium.layers.custom_activations import MaxMin\n",
    "from orthogonium.losses import LossXent, CosineLoss\n",
    "from orthogonium.losses import VRA\n",
    "from orthogonium.model_factory.models_factory import StagedCNN, PatchBasedExapandedCNN\n",
    "\n",
    "# Enable benchmark mode and set matmul precision for performance tuning\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.set_float32_matmul_precision(\"medium\")\n"
   ],
   "id": "54c7e322929ba6a2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Training Settings\n",
    "\n",
    "You can play with the training settings to explore different configurations and compare their performance. The settings include:\n",
    "\n",
    "**Training settings include:**\n",
    "- **non_robust:** Cosine Similarity loss training.\n",
    "- **mildly_robust:** Cross Entropy Loss includes a high margin targeting a VRA of 36/255, resulting in 42% VRA.\n",
    "- **robust:** Similar to mildly robust, but with settings that push towards 72/255 verified robust accuracy, resulting in 47% VRA.\n",
    "\n",
    "\n",
    "> Note: The aim here is to show the training flow rather than reach state-of-the-art performance.\n",
    "\n",
    "## Training Settings Performance\n",
    "\n",
    "| Setting       | Epochs | Accuracy | Verified Robust Accuracy (VRA) |\n",
    "|---------------|--------|----------|--------------------------------|\n",
    "| **non_robust**    | 30     | 88.5%    | 0%                             |\n",
    "| **mildly_robust** | 150    | 75%      | 42%                            |\n",
    "| **robust**        | 150    | 71%      | 47%                            |\n",
    "\n",
    "These configurations are stored in the `settings` dictionary.\n"
   ],
   "id": "2ee069e5694ccd2d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "settings = {\n",
    "    \"non_robust\": {\n",
    "        \"loss\": CosineLoss,\n",
    "        \"epochs\": 30,\n",
    "    },\n",
    "    \"mildly_robust\": {\n",
    "        \"loss\": ClassParam(\n",
    "            LossXent,\n",
    "            n_classes=10,\n",
    "            offset=(math.sqrt(2) / 0.1983) * (36 / 255),  # aiming for 36/255 verified robust accuracy\n",
    "            temperature=0.25,\n",
    "        ),\n",
    "        \"epochs\": 150,\n",
    "    },\n",
    "    \"robust\": {\n",
    "        \"loss\": ClassParam(\n",
    "            LossXent,\n",
    "            n_classes=10,\n",
    "            offset=(math.sqrt(2) / 0.1983) * (72 / 255),  # aiming for 72/255 verified robust accuracy\n",
    "            temperature=0.25,\n",
    "        ),\n",
    "        \"epochs\": 150,\n",
    "    },\n",
    "}\n"
   ],
   "id": "337a713cc4e13f55"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Data Module: CIFAR10\n",
    "\n",
    "We create a `LightningDataModule` to load and preprocess the CIFAR10 training and validation datasets.\n",
    "\n",
    "The training dataloader applies several transforms:\n",
    "- Random resized cropping\n",
    "- Random horizontal flip\n",
    "- Normalization using precomputed mean and standard deviation\n",
    "\n",
    "The validation dataloader only applies tensor conversion and normalization.\n",
    "\n"
   ],
   "id": "eec8549d5fa315b5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class Cifar10DataModule(LightningDataModule):\n",
    "    # Dataset configuration\n",
    "    _BATCH_SIZE = 256\n",
    "    _NUM_WORKERS = 8  # Number of parallel processes for data loading\n",
    "    _PREPROCESSING_PARAMS = {\n",
    "        \"img_mean\": (0.41757566, 0.26098573, 0.25888634),\n",
    "        \"img_std\": (0.21938758, 0.1983, 0.19342837),\n",
    "        \"crop_size\": 32,\n",
    "        \"horizontal_flip_prob\": 0.5,\n",
    "        \"random_resized_crop_params\": {\n",
    "            \"scale\": (0.5, 1.0),\n",
    "            \"ratio\": (3.0 / 4.0, 4.0 / 3.0),\n",
    "        },\n",
    "    }\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        # Define the transformations for training data\n",
    "        transform = Compose(\n",
    "            [\n",
    "                RandomResizedCrop(\n",
    "                    self._PREPROCESSING_PARAMS[\"crop_size\"],\n",
    "                    **self._PREPROCESSING_PARAMS[\"random_resized_crop_params\"],\n",
    "                ),\n",
    "                RandomHorizontalFlip(self._PREPROCESSING_PARAMS[\"horizontal_flip_prob\"]),\n",
    "                # Uncomment the following line to use RandAugment\n",
    "                # RandAugment(**self._PREPROCESSING_PARAMS[\"randaug_params\"]),\n",
    "                ToTensor(),\n",
    "                Normalize(\n",
    "                    mean=self._PREPROCESSING_PARAMS[\"img_mean\"],\n",
    "                    std=self._PREPROCESSING_PARAMS[\"img_std\"],\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        train_dataset = CIFAR10(\n",
    "            root=\"./data\",\n",
    "            train=True,\n",
    "            download=True,\n",
    "            transform=transform,\n",
    "        )\n",
    "\n",
    "        return DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=self._BATCH_SIZE,\n",
    "            num_workers=self._NUM_WORKERS,\n",
    "            prefetch_factor=2,\n",
    "            shuffle=True,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        # Define the transformations for validation data\n",
    "        transform = Compose(\n",
    "            [\n",
    "                ToTensor(),\n",
    "                Normalize(\n",
    "                    mean=self._PREPROCESSING_PARAMS[\"img_mean\"],\n",
    "                    std=self._PREPROCESSING_PARAMS[\"img_std\"],\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        val_dataset = CIFAR10(\n",
    "            root=\"./data\",\n",
    "            train=False,\n",
    "            download=True,\n",
    "            transform=transform,\n",
    "        )\n",
    "\n",
    "        return DataLoader(\n",
    "            val_dataset,\n",
    "            batch_size=self._BATCH_SIZE,\n",
    "            num_workers=self._NUM_WORKERS,\n",
    "            shuffle=False,\n",
    "        )\n"
   ],
   "id": "1e578065843cfeb2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Classification Model Module\n",
    "\n",
    "We now define a `LightningModule` that wraps our CNN model. The network is built using the `PatchBasedExapandedCNN` factory method from *orthogonium*.\n",
    "\n",
    "Key components include:\n",
    "- The custom CNN model architecture.\n",
    "- The loss function (set based on the selected training configuration).\n",
    "- Training and validation steps that compute and log both accuracy and verified robust accuracy (VRA).\n",
    "- The `configure_optimizers` method which sets up the Adam optimizer with schedule-free updates.\n"
   ],
   "id": "617cfc5c06ab2d75"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class ClassificationLightningModule(LightningModule):\n",
    "    def __init__(self, num_classes=10, loss=None):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.model = PatchBasedExapandedCNN(\n",
    "            img_shape=(3, 32, 32),\n",
    "            dim=256,\n",
    "            depth=12,\n",
    "            kernel_size=3,\n",
    "            patch_size=2,\n",
    "            expand_factor=2,\n",
    "            groups=None,\n",
    "            n_classes=10,\n",
    "            skip=True,\n",
    "            conv=ClassParam(\n",
    "                AdaptiveOrthoConv2d,\n",
    "                bias=False,\n",
    "                padding=\"same\",\n",
    "                padding_mode=\"zeros\",\n",
    "            ),\n",
    "            act=ClassParam(MaxMin),\n",
    "            pool=ClassParam(\n",
    "                AdaptiveOrthoConv2d,\n",
    "                in_channels=256,\n",
    "                out_channels=256,\n",
    "                groups=128,\n",
    "                bias=False,\n",
    "                padding=0,\n",
    "                kernel_size=16,\n",
    "                stride=16,\n",
    "            ),\n",
    "            lin=ClassParam(OrthoLinear, bias=False),\n",
    "            norm=None,\n",
    "        )\n",
    "        self.criteria = loss() if loss is not None else torch.nn.CrossEntropyLoss()\n",
    "        self.train_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
    "        self.val_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
    "        self.train_vra = torchmetrics.MeanMetric()\n",
    "        self.val_vra = torchmetrics.MeanMetric()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        self.model.train()\n",
    "        img, label = batch\n",
    "        y_hat = self.model(img)\n",
    "        loss = self.criteria(y_hat, label)\n",
    "        self.train_acc(y_hat, label)\n",
    "        self.train_vra(\n",
    "            VRA(\n",
    "                y_hat,\n",
    "                label,\n",
    "                L=1 / min(Cifar10DataModule._PREPROCESSING_PARAMS[\"img_std\"]),\n",
    "                eps=36 / 255,\n",
    "                last_layer_type=\"global\",\n",
    "            )\n",
    "        )\n",
    "        self.log(\"loss\", loss, on_epoch=True, on_step=True, prog_bar=True, sync_dist=True)\n",
    "        self.log(\"accuracy\", self.train_acc, on_epoch=True, on_step=True, prog_bar=True, sync_dist=True)\n",
    "        self.log(\"vra\", self.train_vra, on_epoch=True, on_step=True, prog_bar=True, sync_dist=False)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        self.model.eval()\n",
    "        img, label = batch\n",
    "        y_hat = self.model(img)\n",
    "        loss = self.criteria(y_hat, label)\n",
    "        self.val_acc(y_hat, label)\n",
    "        self.val_vra(\n",
    "            VRA(\n",
    "                y_hat,\n",
    "                label,\n",
    "                L=1 / min(Cifar10DataModule._PREPROCESSING_PARAMS[\"img_std\"]),\n",
    "                eps=36 / 255,\n",
    "                last_layer_type=\"global\",\n",
    "            )\n",
    "        )\n",
    "        self.log(\"val_loss\", loss, on_epoch=True, on_step=False, prog_bar=True, sync_dist=True)\n",
    "        self.log(\"val_accuracy\", self.val_acc, on_epoch=True, on_step=False, prog_bar=True, sync_dist=True)\n",
    "        self.log(\"val_vra\", self.val_vra, on_epoch=True, on_step=False, prog_bar=True, sync_dist=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # Setup the Adam optimizer with schedule-free updates.\n",
    "        optimizer = schedulefree.AdamWScheduleFree(self.parameters(), lr=5e-3, weight_decay=0)\n",
    "        optimizer.train()\n",
    "        self.hparams[\"lr\"] = optimizer.param_groups[0][\"lr\"]\n",
    "        return optimizer\n"
   ],
   "id": "d3bc13596b867137"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Training Routine\n",
    "\n",
    "For example, to run a **non robust** training setting, set:\n",
    "\n",
    "```python\n",
    "train_setting = \"non_robust\"\n"
   ],
   "id": "7442d6e9fdde2433"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Select the training setting manually.\n",
    "train_setting = \"non_robust\"  # Options: \"non_robust\", \"mildly_robust\", or \"robust\"\n",
    "\n",
    "# Get the corresponding loss function and number of epochs from the settings.\n",
    "current_setting = settings[train_setting]\n",
    "\n",
    "# Instantiate the classification model and data module.\n",
    "classification_module = ClassificationLightningModule(num_classes=10, loss=current_setting[\"loss\"])\n",
    "data_module = Cifar10DataModule()\n",
    "\n",
    "# Optionally, set up a logger or callbacks if needed.\n",
    "# For example, if using Wandb:\n",
    "# from lightning.pytorch.loggers import WandbLogger\n",
    "# wandb_logger = WandbLogger(project=\"lipschitz-robust-cifar10\", log_model=True)\n",
    "# checkpoint_callback = pl_callbacks.ModelCheckpoint(\n",
    "#     monitor=\"loss\",\n",
    "#     mode=\"min\",\n",
    "#     save_top_k=1,\n",
    "#     save_last=True,\n",
    "#     dirpath=f\"./checkpoints/{wandb_logger.experiment.dir}\",\n",
    "# )\n",
    "\n",
    "trainer = Trainer(\n",
    "    accelerator=\"gpu\",\n",
    "    devices=-1,             # Use all available GPUs\n",
    "    num_nodes=1,            # Number of nodes\n",
    "    strategy=\"ddp\",         # Distributed strategy\n",
    "    precision=\"bf16-mixed\", # Mixed precision training\n",
    "    max_epochs=current_setting[\"epochs\"],\n",
    "    enable_model_summary=True,\n",
    "    # logger=[wandb_logger],  # Uncomment to enable Wandb logging\n",
    "    logger=False,\n",
    "    callbacks=[\n",
    "        # You can add callbacks here, e.g.:\n",
    "        # pl_callbacks.LearningRateFinder(max_lr=0.05),\n",
    "        # checkpoint_callback,\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Print a summary of the model\n",
    "summary(classification_module, input_size=(1, 3, 32, 32))\n",
    "\n",
    "# Start training\n",
    "trainer.fit(classification_module, data_module)\n",
    "\n",
    "# Optionally, you can save the trained model afterwards:\n",
    "# torch.save(classification_module.model.state_dict(), \"single_stage.pth\")\n"
   ],
   "id": "17b7575b29534e21"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Next Steps\n",
    "\n",
    "- **Model Evaluation:** You can add a new cell to perform model evaluation or predictions.\n",
    "- **Logging and Checkpoints:** To enable model logging or checkpoint saving, uncomment the corresponding lines and configure as needed.\n",
    "- **Experiment with Settings:** Change the `train_setting` variable to `\"mildly_robust\"` or `\"robust\"` to experiment with other training configurations.\n"
   ],
   "id": "399725e628d1393a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
