
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="../linear/">
      
      
        <link rel="next" href="../activations/">
      
      
      <link rel="icon" href="../../assets/banner.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.5.49">
    
    
      
        <title>reparametrizers - orthogonium</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.6f8fc17f.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../assets/_mkdocstrings.css">
    
      <link rel="stylesheet" href="../../css/custom.css">
    
      <link rel="stylesheet" href="../../css/ansi-colours.css">
    
      <link rel="stylesheet" href="../../css/jupyter-cells.css">
    
      <link rel="stylesheet" href="../../css/pandas-dataframe.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="dark" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#orthogonium.reparametrizers" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="orthogonium" class="md-header__button md-logo" aria-label="orthogonium" data-md-component="logo">
      
  <img src="../../assets/banner.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            orthogonium
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              reparametrizers
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="dark" data-md-color-accent="indigo"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 6H7c-3.31 0-6 2.69-6 6s2.69 6 6 6h10c3.31 0 6-2.69 6-6s-2.69-6-6-6m0 10H7c-2.21 0-4-1.79-4-4s1.79-4 4-4h10c2.21 0 4 1.79 4 4s-1.79 4-4 4M7 9c-1.66 0-3 1.34-3 3s1.34 3 3 3 3-1.34 3-3-1.34-3-3-3"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h10a5 5 0 0 0 5-5 5 5 0 0 0-5-5m0 8a3 3 0 0 1-3-3 3 3 0 0 1 3-3 3 3 0 0 1 3 3 3 3 0 0 1-3 3"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/thib-s/orthogonium" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.7.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
  </div>
  <div class="md-source__repository">
    thib-s/orthogonium
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="orthogonium" class="md-nav__button md-logo" aria-label="orthogonium" data-md-component="logo">
      
  <img src="../../assets/banner.png" alt="logo">

    </a>
    orthogonium
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/thib-s/orthogonium" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.7.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
  </div>
  <div class="md-source__repository">
    thib-s/orthogonium
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" checked>
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    API Reference
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            API Reference
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../conv/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    convolutions
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../linear/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    linear layers
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    reparametrizers
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    reparametrizers
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#orthogonium.reparametrizers" class="md-nav__link">
    <span class="md-ellipsis">
      reparametrizers
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#orthogonium.reparametrizers.BatchedBjorckOrthogonalization" class="md-nav__link">
    <span class="md-ellipsis">
      BatchedBjorckOrthogonalization
    </span>
  </a>
  
    <nav class="md-nav" aria-label="BatchedBjorckOrthogonalization">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#orthogonium.reparametrizers.BatchedBjorckOrthogonalization.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#orthogonium.reparametrizers.BatchedBjorckOrthogonalization.forward" class="md-nav__link">
    <span class="md-ellipsis">
      forward
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#orthogonium.reparametrizers.BatchedCholeskyOrthogonalization" class="md-nav__link">
    <span class="md-ellipsis">
      BatchedCholeskyOrthogonalization
    </span>
  </a>
  
    <nav class="md-nav" aria-label="BatchedCholeskyOrthogonalization">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#orthogonium.reparametrizers.BatchedCholeskyOrthogonalization.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#orthogonium.reparametrizers.BatchedCholeskyOrthogonalization.forward" class="md-nav__link">
    <span class="md-ellipsis">
      forward
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#orthogonium.reparametrizers.BatchedExponentialOrthogonalization" class="md-nav__link">
    <span class="md-ellipsis">
      BatchedExponentialOrthogonalization
    </span>
  </a>
  
    <nav class="md-nav" aria-label="BatchedExponentialOrthogonalization">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#orthogonium.reparametrizers.BatchedExponentialOrthogonalization.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#orthogonium.reparametrizers.BatchedIdentity" class="md-nav__link">
    <span class="md-ellipsis">
      BatchedIdentity
    </span>
  </a>
  
    <nav class="md-nav" aria-label="BatchedIdentity">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#orthogonium.reparametrizers.BatchedIdentity.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#orthogonium.reparametrizers.BatchedPowerIteration" class="md-nav__link">
    <span class="md-ellipsis">
      BatchedPowerIteration
    </span>
  </a>
  
    <nav class="md-nav" aria-label="BatchedPowerIteration">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#orthogonium.reparametrizers.BatchedPowerIteration.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#orthogonium.reparametrizers.BatchedQROrthogonalization" class="md-nav__link">
    <span class="md-ellipsis">
      BatchedQROrthogonalization
    </span>
  </a>
  
    <nav class="md-nav" aria-label="BatchedQROrthogonalization">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#orthogonium.reparametrizers.BatchedQROrthogonalization.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#orthogonium.reparametrizers.BatchedQROrthogonalization.forward" class="md-nav__link">
    <span class="md-ellipsis">
      forward
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#orthogonium.reparametrizers.L2Normalize" class="md-nav__link">
    <span class="md-ellipsis">
      L2Normalize
    </span>
  </a>
  
    <nav class="md-nav" aria-label="L2Normalize">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#orthogonium.reparametrizers.L2Normalize.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#orthogonium.reparametrizers.OrthoParams" class="md-nav__link">
    <span class="md-ellipsis">
      OrthoParams
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../activations/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    activations
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../losses/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    losses
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../CONTRIBUTING/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Contributing
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#orthogonium.reparametrizers" class="md-nav__link">
    <span class="md-ellipsis">
      reparametrizers
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#orthogonium.reparametrizers.BatchedBjorckOrthogonalization" class="md-nav__link">
    <span class="md-ellipsis">
      BatchedBjorckOrthogonalization
    </span>
  </a>
  
    <nav class="md-nav" aria-label="BatchedBjorckOrthogonalization">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#orthogonium.reparametrizers.BatchedBjorckOrthogonalization.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#orthogonium.reparametrizers.BatchedBjorckOrthogonalization.forward" class="md-nav__link">
    <span class="md-ellipsis">
      forward
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#orthogonium.reparametrizers.BatchedCholeskyOrthogonalization" class="md-nav__link">
    <span class="md-ellipsis">
      BatchedCholeskyOrthogonalization
    </span>
  </a>
  
    <nav class="md-nav" aria-label="BatchedCholeskyOrthogonalization">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#orthogonium.reparametrizers.BatchedCholeskyOrthogonalization.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#orthogonium.reparametrizers.BatchedCholeskyOrthogonalization.forward" class="md-nav__link">
    <span class="md-ellipsis">
      forward
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#orthogonium.reparametrizers.BatchedExponentialOrthogonalization" class="md-nav__link">
    <span class="md-ellipsis">
      BatchedExponentialOrthogonalization
    </span>
  </a>
  
    <nav class="md-nav" aria-label="BatchedExponentialOrthogonalization">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#orthogonium.reparametrizers.BatchedExponentialOrthogonalization.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#orthogonium.reparametrizers.BatchedIdentity" class="md-nav__link">
    <span class="md-ellipsis">
      BatchedIdentity
    </span>
  </a>
  
    <nav class="md-nav" aria-label="BatchedIdentity">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#orthogonium.reparametrizers.BatchedIdentity.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#orthogonium.reparametrizers.BatchedPowerIteration" class="md-nav__link">
    <span class="md-ellipsis">
      BatchedPowerIteration
    </span>
  </a>
  
    <nav class="md-nav" aria-label="BatchedPowerIteration">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#orthogonium.reparametrizers.BatchedPowerIteration.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#orthogonium.reparametrizers.BatchedQROrthogonalization" class="md-nav__link">
    <span class="md-ellipsis">
      BatchedQROrthogonalization
    </span>
  </a>
  
    <nav class="md-nav" aria-label="BatchedQROrthogonalization">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#orthogonium.reparametrizers.BatchedQROrthogonalization.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#orthogonium.reparametrizers.BatchedQROrthogonalization.forward" class="md-nav__link">
    <span class="md-ellipsis">
      forward
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#orthogonium.reparametrizers.L2Normalize" class="md-nav__link">
    <span class="md-ellipsis">
      L2Normalize
    </span>
  </a>
  
    <nav class="md-nav" aria-label="L2Normalize">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#orthogonium.reparametrizers.L2Normalize.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#orthogonium.reparametrizers.OrthoParams" class="md-nav__link">
    <span class="md-ellipsis">
      OrthoParams
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
  


  <h1>reparametrizers</h1>

<div class="doc doc-object doc-module">



<a id="orthogonium.reparametrizers"></a>
    <div class="doc doc-contents first">








  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h2 id="orthogonium.reparametrizers.BatchedBjorckOrthogonalization" class="doc doc-heading">
            <code>BatchedBjorckOrthogonalization</code>


<a href="#orthogonium.reparametrizers.BatchedBjorckOrthogonalization" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="torch.nn.Module">Module</span></code></p>







              <details class="quote">
                <summary>Source code in <code>orthogonium\reparametrizers.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">BatchedBjorckOrthogonalization</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">weight_shape</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">niters</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">pass_through</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initialize the BatchedBjorckOrthogonalization module.</span>

<span class="sd">        This module implements the Björck orthogonalization method, which iteratively refines</span>
<span class="sd">        a weight matrix towards orthogonality. The method is especially effective when the</span>
<span class="sd">        weight matrix columns are nearly orthonormal. It balances computational efficiency</span>
<span class="sd">        with convergence speed through a user-defined `beta` parameter and iteration count.</span>

<span class="sd">        Args:</span>
<span class="sd">            weight_shape (tuple): The shape of the weight matrix to be orthogonalized.</span>
<span class="sd">            beta (float): Coefficient controlling the convergence of the orthogonalization process.</span>
<span class="sd">                Default is 0.5.</span>
<span class="sd">            niters (int): Number of iterations for the orthogonalization algorithm. Default is 12.</span>
<span class="sd">            pass_through (bool): If True, most iterations are performed without gradient computation,</span>
<span class="sd">                which can improve efficiency.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weight_shape</span> <span class="o">=</span> <span class="n">weight_shape</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">beta</span> <span class="o">=</span> <span class="n">beta</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">niters</span> <span class="o">=</span> <span class="n">niters</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pass_through</span> <span class="o">=</span> <span class="n">pass_through</span>
        <span class="k">if</span> <span class="n">weight_shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">weight_shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">wwtw_op</span> <span class="o">=</span> <span class="n">BatchedBjorckOrthogonalization</span><span class="o">.</span><span class="n">wwt_w_op</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">wwtw_op</span> <span class="o">=</span> <span class="n">BatchedBjorckOrthogonalization</span><span class="o">.</span><span class="n">w_wtw_op</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">BatchedBjorckOrthogonalization</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">w_wtw_op</span><span class="p">(</span><span class="n">w</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">w</span> <span class="o">@</span> <span class="p">(</span><span class="n">w</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">)</span> <span class="o">@</span> <span class="n">w</span><span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">wwt_w_op</span><span class="p">(</span><span class="n">w</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">w</span> <span class="o">@</span> <span class="n">w</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">))</span> <span class="o">@</span> <span class="n">w</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">w</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Apply the Björck orthogonalization process to the weight matrix.</span>

<span class="sd">        The algorithm adjusts the input matrix to approximate the closest orthogonal matrix</span>
<span class="sd">        by iteratively applying transformations based on the Björck algorithm.</span>

<span class="sd">        Args:</span>
<span class="sd">            w (torch.Tensor): The weight matrix to be orthogonalized.</span>

<span class="sd">        Returns:</span>
<span class="sd">            torch.Tensor: The orthogonalized weight matrix.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pass_through</span><span class="p">:</span>
            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">niters</span><span class="p">):</span>
                    <span class="n">w</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta</span><span class="p">)</span> <span class="o">*</span> <span class="n">w</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">wwtw_op</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>
            <span class="c1"># Final iteration without no_grad, using parameters:</span>
            <span class="n">w</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta</span><span class="p">)</span> <span class="o">*</span> <span class="n">w</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">wwtw_op</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">niters</span><span class="p">):</span>
                <span class="n">w</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta</span><span class="p">)</span> <span class="o">*</span> <span class="n">w</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">wwtw_op</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">w</span>

    <span class="k">def</span> <span class="nf">right_inverse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">w</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">w</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="orthogonium.reparametrizers.BatchedBjorckOrthogonalization.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">weight_shape</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">niters</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">pass_through</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></code>

<a href="#orthogonium.reparametrizers.BatchedBjorckOrthogonalization.__init__" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Initialize the BatchedBjorckOrthogonalization module.</p>
<p>This module implements the Björck orthogonalization method, which iteratively refines
a weight matrix towards orthogonality. The method is especially effective when the
weight matrix columns are nearly orthonormal. It balances computational efficiency
with convergence speed through a user-defined <code>beta</code> parameter and iteration count.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>weight_shape</code>
            </td>
            <td>
                  <code>tuple</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The shape of the weight matrix to be orthogonalized.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>beta</code>
            </td>
            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Coefficient controlling the convergence of the orthogonalization process.
Default is 0.5.</p>
              </div>
            </td>
            <td>
                  <code>0.5</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>niters</code>
            </td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of iterations for the orthogonalization algorithm. Default is 12.</p>
              </div>
            </td>
            <td>
                  <code>12</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>pass_through</code>
            </td>
            <td>
                  <code>bool</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If True, most iterations are performed without gradient computation,
which can improve efficiency.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>orthogonium\reparametrizers.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">weight_shape</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">niters</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">pass_through</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Initialize the BatchedBjorckOrthogonalization module.</span>

<span class="sd">    This module implements the Björck orthogonalization method, which iteratively refines</span>
<span class="sd">    a weight matrix towards orthogonality. The method is especially effective when the</span>
<span class="sd">    weight matrix columns are nearly orthonormal. It balances computational efficiency</span>
<span class="sd">    with convergence speed through a user-defined `beta` parameter and iteration count.</span>

<span class="sd">    Args:</span>
<span class="sd">        weight_shape (tuple): The shape of the weight matrix to be orthogonalized.</span>
<span class="sd">        beta (float): Coefficient controlling the convergence of the orthogonalization process.</span>
<span class="sd">            Default is 0.5.</span>
<span class="sd">        niters (int): Number of iterations for the orthogonalization algorithm. Default is 12.</span>
<span class="sd">        pass_through (bool): If True, most iterations are performed without gradient computation,</span>
<span class="sd">            which can improve efficiency.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">weight_shape</span> <span class="o">=</span> <span class="n">weight_shape</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">beta</span> <span class="o">=</span> <span class="n">beta</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">niters</span> <span class="o">=</span> <span class="n">niters</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">pass_through</span> <span class="o">=</span> <span class="n">pass_through</span>
    <span class="k">if</span> <span class="n">weight_shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">weight_shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">wwtw_op</span> <span class="o">=</span> <span class="n">BatchedBjorckOrthogonalization</span><span class="o">.</span><span class="n">wwt_w_op</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">wwtw_op</span> <span class="o">=</span> <span class="n">BatchedBjorckOrthogonalization</span><span class="o">.</span><span class="n">w_wtw_op</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">BatchedBjorckOrthogonalization</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="orthogonium.reparametrizers.BatchedBjorckOrthogonalization.forward" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">forward</span><span class="p">(</span><span class="n">w</span><span class="p">)</span></code>

<a href="#orthogonium.reparametrizers.BatchedBjorckOrthogonalization.forward" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Apply the Björck orthogonalization process to the weight matrix.</p>
<p>The algorithm adjusts the input matrix to approximate the closest orthogonal matrix
by iteratively applying transformations based on the Björck algorithm.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>w</code>
            </td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The weight matrix to be orthogonalized.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>torch.Tensor: The orthogonalized weight matrix.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>orthogonium\reparametrizers.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">w</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Apply the Björck orthogonalization process to the weight matrix.</span>

<span class="sd">    The algorithm adjusts the input matrix to approximate the closest orthogonal matrix</span>
<span class="sd">    by iteratively applying transformations based on the Björck algorithm.</span>

<span class="sd">    Args:</span>
<span class="sd">        w (torch.Tensor): The weight matrix to be orthogonalized.</span>

<span class="sd">    Returns:</span>
<span class="sd">        torch.Tensor: The orthogonalized weight matrix.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pass_through</span><span class="p">:</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">niters</span><span class="p">):</span>
                <span class="n">w</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta</span><span class="p">)</span> <span class="o">*</span> <span class="n">w</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">wwtw_op</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>
        <span class="c1"># Final iteration without no_grad, using parameters:</span>
        <span class="n">w</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta</span><span class="p">)</span> <span class="o">*</span> <span class="n">w</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">wwtw_op</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">niters</span><span class="p">):</span>
            <span class="n">w</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta</span><span class="p">)</span> <span class="o">*</span> <span class="n">w</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">wwtw_op</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">w</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="orthogonium.reparametrizers.BatchedCholeskyOrthogonalization" class="doc doc-heading">
            <code>BatchedCholeskyOrthogonalization</code>


<a href="#orthogonium.reparametrizers.BatchedCholeskyOrthogonalization" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="torch.nn.Module">Module</span></code></p>







              <details class="quote">
                <summary>Source code in <code>orthogonium\reparametrizers.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">BatchedCholeskyOrthogonalization</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">weight_shape</span><span class="p">,</span> <span class="n">stable</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initialize the BatchedCholeskyOrthogonalization module.</span>

<span class="sd">        This module orthogonalizes a weight matrix using the Cholesky decomposition method.</span>
<span class="sd">        It first computes the positive definite matrix \( V V^T \), then performs a Cholesky</span>
<span class="sd">        decomposition to obtain a lower triangular matrix. Solving the resulting triangular</span>
<span class="sd">        system yields an orthogonal matrix. This method is efficient and numerically stable,</span>
<span class="sd">        making it suitable for a wide range of applications.</span>

<span class="sd">        Args:</span>
<span class="sd">            weight_shape (tuple): The shape of the weight matrix.</span>
<span class="sd">            stable (bool): Whether to use the stable version of the Cholesky-based orthogonalization</span>
<span class="sd">                function, which adds a small positive diagonal element to ensure numerical stability.</span>
<span class="sd">                Default is False.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weight_shape</span> <span class="o">=</span> <span class="n">weight_shape</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">BatchedCholeskyOrthogonalization</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">stable</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">orth</span> <span class="o">=</span> <span class="n">BatchedCholeskyOrthogonalization</span><span class="o">.</span><span class="n">CholeskyOrthfn_stable</span><span class="o">.</span><span class="n">apply</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">orth</span> <span class="o">=</span> <span class="n">BatchedCholeskyOrthogonalization</span><span class="o">.</span><span class="n">CholeskyOrthfn</span><span class="o">.</span><span class="n">apply</span>

    <span class="c1"># @staticmethod</span>
    <span class="c1"># def orth(X):</span>
    <span class="c1">#     S = X @ X.mT</span>
    <span class="c1">#     eps = S.diagonal(dim1=1, dim2=2).mean(1).mul(1e-3).detach()</span>
    <span class="c1">#     eye = torch.eye(S.size(-1), dtype=S.dtype, device=S.device)</span>
    <span class="c1">#     S = S + eps.view(-1, 1, 1) * eye.unsqueeze(0)</span>
    <span class="c1">#     L = torch.linalg.cholesky(S)</span>
    <span class="c1">#     W = torch.linalg.solve_triangular(L, X, upper=False)</span>
    <span class="c1">#     return W</span>

    <span class="k">class</span> <span class="nc">CholeskyOrthfn</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">Function</span><span class="p">):</span>
        <span class="nd">@staticmethod</span>
        <span class="c1"># def forward(ctx, X):</span>
        <span class="c1">#     S = X @ X.mT</span>
        <span class="c1">#     eps = S.diagonal(dim1=1, dim2=2).mean(1).mul(1e-3)</span>
        <span class="c1">#     eye = torch.eye(S.size(-1), dtype=S.dtype, device=S.device)</span>
        <span class="c1">#     S = S + eps.view(-1, 1, 1) * eye.unsqueeze(0)</span>
        <span class="c1">#     L = torch.linalg.cholesky(S)</span>
        <span class="c1">#     W = torch.linalg.solve_triangular(L, X, upper=False)</span>
        <span class="c1">#     ctx.save_for_backward(W, L)</span>
        <span class="c1">#     return W</span>
        <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">ctx</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
            <span class="n">S</span> <span class="o">=</span> <span class="n">X</span> <span class="o">@</span> <span class="n">X</span><span class="o">.</span><span class="n">mT</span>
            <span class="n">eps</span> <span class="o">=</span> <span class="mf">1e-5</span>  <span class="c1"># A common stable choice</span>
            <span class="n">S</span> <span class="o">=</span> <span class="n">S</span> <span class="o">+</span> <span class="n">eps</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span>
                <span class="n">S</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">S</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">S</span><span class="o">.</span><span class="n">device</span>
            <span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">L</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">cholesky</span><span class="p">(</span><span class="n">S</span><span class="p">)</span>
            <span class="n">W</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">solve_triangular</span><span class="p">(</span><span class="n">L</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">upper</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="n">ctx</span><span class="o">.</span><span class="n">save_for_backward</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">L</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">W</span>

        <span class="nd">@staticmethod</span>
        <span class="k">def</span> <span class="nf">backward</span><span class="p">(</span><span class="n">ctx</span><span class="p">,</span> <span class="n">grad_output</span><span class="p">):</span>
            <span class="n">W</span><span class="p">,</span> <span class="n">L</span> <span class="o">=</span> <span class="n">ctx</span><span class="o">.</span><span class="n">saved_tensors</span>
            <span class="n">LmT</span> <span class="o">=</span> <span class="n">L</span><span class="o">.</span><span class="n">mT</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>
            <span class="n">gB</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">solve_triangular</span><span class="p">(</span><span class="n">LmT</span><span class="p">,</span> <span class="n">grad_output</span><span class="p">,</span> <span class="n">upper</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">gA</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span><span class="n">gB</span> <span class="o">@</span> <span class="n">W</span><span class="o">.</span><span class="n">mT</span><span class="p">)</span><span class="o">.</span><span class="n">tril</span><span class="p">()</span>
            <span class="n">gS</span> <span class="o">=</span> <span class="p">(</span><span class="n">LmT</span> <span class="o">@</span> <span class="n">gA</span><span class="p">)</span><span class="o">.</span><span class="n">tril</span><span class="p">()</span>
            <span class="n">gS</span> <span class="o">=</span> <span class="n">gS</span> <span class="o">+</span> <span class="n">gS</span><span class="o">.</span><span class="n">tril</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">mT</span>
            <span class="n">gS</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">solve_triangular</span><span class="p">(</span><span class="n">LmT</span><span class="p">,</span> <span class="n">gS</span><span class="p">,</span> <span class="n">upper</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">gX</span> <span class="o">=</span> <span class="n">gS</span> <span class="o">@</span> <span class="n">W</span> <span class="o">+</span> <span class="n">gB</span>
            <span class="k">return</span> <span class="n">gX</span>

    <span class="k">class</span> <span class="nc">CholeskyOrthfn_stable</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">Function</span><span class="p">):</span>
        <span class="nd">@staticmethod</span>
        <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">ctx</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
            <span class="n">S</span> <span class="o">=</span> <span class="n">X</span> <span class="o">@</span> <span class="n">X</span><span class="o">.</span><span class="n">mT</span>
            <span class="n">eps</span> <span class="o">=</span> <span class="mf">1e-5</span>  <span class="c1"># A common stable choice</span>
            <span class="n">S</span> <span class="o">=</span> <span class="n">S</span> <span class="o">+</span> <span class="n">eps</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span>
                <span class="n">S</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">S</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">S</span><span class="o">.</span><span class="n">device</span>
            <span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">L</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">cholesky</span><span class="p">(</span><span class="n">S</span><span class="p">)</span>
            <span class="n">W</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">solve_triangular</span><span class="p">(</span><span class="n">L</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">upper</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="n">ctx</span><span class="o">.</span><span class="n">save_for_backward</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">L</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">W</span>

        <span class="nd">@staticmethod</span>
        <span class="k">def</span> <span class="nf">backward</span><span class="p">(</span><span class="n">ctx</span><span class="p">,</span> <span class="n">grad_output</span><span class="p">):</span>
            <span class="n">X</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">L</span> <span class="o">=</span> <span class="n">ctx</span><span class="o">.</span><span class="n">saved_tensors</span>
            <span class="n">gB</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">solve_triangular</span><span class="p">(</span><span class="n">L</span><span class="o">.</span><span class="n">mT</span><span class="p">,</span> <span class="n">grad_output</span><span class="p">,</span> <span class="n">upper</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">gA</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span><span class="n">gB</span> <span class="o">@</span> <span class="n">W</span><span class="o">.</span><span class="n">mT</span><span class="p">)</span><span class="o">.</span><span class="n">tril</span><span class="p">()</span>
            <span class="n">gS</span> <span class="o">=</span> <span class="p">(</span><span class="n">L</span><span class="o">.</span><span class="n">mT</span> <span class="o">@</span> <span class="n">gA</span><span class="p">)</span><span class="o">.</span><span class="n">tril</span><span class="p">()</span>
            <span class="n">gS</span> <span class="o">=</span> <span class="n">gS</span> <span class="o">+</span> <span class="n">gS</span><span class="o">.</span><span class="n">tril</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">mT</span>
            <span class="n">gS</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">solve_triangular</span><span class="p">(</span><span class="n">L</span><span class="o">.</span><span class="n">mT</span><span class="p">,</span> <span class="n">gS</span><span class="p">,</span> <span class="n">upper</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">gS</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">solve_triangular</span><span class="p">(</span><span class="n">L</span><span class="p">,</span> <span class="n">gS</span><span class="p">,</span> <span class="n">upper</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">left</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="n">gX</span> <span class="o">=</span> <span class="n">gS</span> <span class="o">@</span> <span class="n">X</span> <span class="o">+</span> <span class="n">gB</span>
            <span class="k">return</span> <span class="n">gX</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">w</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Apply Cholesky-based orthogonalization to the weight matrix.</span>

<span class="sd">        This method constructs a symmetric positive definite matrix from the input weight</span>
<span class="sd">        matrix, performs Cholesky decomposition, and solves the triangular system to produce</span>
<span class="sd">        an orthogonal matrix. It mimics the results of the Gram-Schmidt process but with</span>
<span class="sd">        improved numerical stability.</span>

<span class="sd">        Args:</span>
<span class="sd">            w (torch.Tensor): The weight matrix to be orthogonalized.</span>

<span class="sd">        Returns:</span>
<span class="sd">            torch.Tensor: The orthogonalized weight matrix.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">orth</span><span class="p">(</span><span class="n">w</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">weight_shape</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">right_inverse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">w</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">w</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="orthogonium.reparametrizers.BatchedCholeskyOrthogonalization.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">weight_shape</span><span class="p">,</span> <span class="n">stable</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></code>

<a href="#orthogonium.reparametrizers.BatchedCholeskyOrthogonalization.__init__" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Initialize the BatchedCholeskyOrthogonalization module.</p>
<p>This module orthogonalizes a weight matrix using the Cholesky decomposition method.
It first computes the positive definite matrix <span class="arithmatex">\( V V^T \)</span>, then performs a Cholesky
decomposition to obtain a lower triangular matrix. Solving the resulting triangular
system yields an orthogonal matrix. This method is efficient and numerically stable,
making it suitable for a wide range of applications.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>weight_shape</code>
            </td>
            <td>
                  <code>tuple</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The shape of the weight matrix.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>stable</code>
            </td>
            <td>
                  <code>bool</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Whether to use the stable version of the Cholesky-based orthogonalization
function, which adds a small positive diagonal element to ensure numerical stability.
Default is False.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>orthogonium\reparametrizers.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">weight_shape</span><span class="p">,</span> <span class="n">stable</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Initialize the BatchedCholeskyOrthogonalization module.</span>

<span class="sd">    This module orthogonalizes a weight matrix using the Cholesky decomposition method.</span>
<span class="sd">    It first computes the positive definite matrix \( V V^T \), then performs a Cholesky</span>
<span class="sd">    decomposition to obtain a lower triangular matrix. Solving the resulting triangular</span>
<span class="sd">    system yields an orthogonal matrix. This method is efficient and numerically stable,</span>
<span class="sd">    making it suitable for a wide range of applications.</span>

<span class="sd">    Args:</span>
<span class="sd">        weight_shape (tuple): The shape of the weight matrix.</span>
<span class="sd">        stable (bool): Whether to use the stable version of the Cholesky-based orthogonalization</span>
<span class="sd">            function, which adds a small positive diagonal element to ensure numerical stability.</span>
<span class="sd">            Default is False.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">weight_shape</span> <span class="o">=</span> <span class="n">weight_shape</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">BatchedCholeskyOrthogonalization</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">stable</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">orth</span> <span class="o">=</span> <span class="n">BatchedCholeskyOrthogonalization</span><span class="o">.</span><span class="n">CholeskyOrthfn_stable</span><span class="o">.</span><span class="n">apply</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">orth</span> <span class="o">=</span> <span class="n">BatchedCholeskyOrthogonalization</span><span class="o">.</span><span class="n">CholeskyOrthfn</span><span class="o">.</span><span class="n">apply</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="orthogonium.reparametrizers.BatchedCholeskyOrthogonalization.forward" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">forward</span><span class="p">(</span><span class="n">w</span><span class="p">)</span></code>

<a href="#orthogonium.reparametrizers.BatchedCholeskyOrthogonalization.forward" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Apply Cholesky-based orthogonalization to the weight matrix.</p>
<p>This method constructs a symmetric positive definite matrix from the input weight
matrix, performs Cholesky decomposition, and solves the triangular system to produce
an orthogonal matrix. It mimics the results of the Gram-Schmidt process but with
improved numerical stability.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>w</code>
            </td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The weight matrix to be orthogonalized.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>torch.Tensor: The orthogonalized weight matrix.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>orthogonium\reparametrizers.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">w</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Apply Cholesky-based orthogonalization to the weight matrix.</span>

<span class="sd">    This method constructs a symmetric positive definite matrix from the input weight</span>
<span class="sd">    matrix, performs Cholesky decomposition, and solves the triangular system to produce</span>
<span class="sd">    an orthogonal matrix. It mimics the results of the Gram-Schmidt process but with</span>
<span class="sd">    improved numerical stability.</span>

<span class="sd">    Args:</span>
<span class="sd">        w (torch.Tensor): The weight matrix to be orthogonalized.</span>

<span class="sd">    Returns:</span>
<span class="sd">        torch.Tensor: The orthogonalized weight matrix.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">orth</span><span class="p">(</span><span class="n">w</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">weight_shape</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="orthogonium.reparametrizers.BatchedExponentialOrthogonalization" class="doc doc-heading">
            <code>BatchedExponentialOrthogonalization</code>


<a href="#orthogonium.reparametrizers.BatchedExponentialOrthogonalization" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="torch.nn.Module">Module</span></code></p>







              <details class="quote">
                <summary>Source code in <code>orthogonium\reparametrizers.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">BatchedExponentialOrthogonalization</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">weight_shape</span><span class="p">,</span> <span class="n">niters</span><span class="o">=</span><span class="mi">7</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initialize the BatchedExponentialOrthogonalization module.</span>

<span class="sd">        This module orthogonalizes a weight matrix using the exponential map of a skew-symmetric</span>
<span class="sd">        matrix. By converting the matrix into a skew-symmetric form and applying the matrix</span>
<span class="sd">        exponential, it produces an orthogonal matrix. This approach is particularly useful</span>
<span class="sd">        in contexts where smooth transitions between matrices are required.</span>

<span class="sd">        Non-square matrices are padded to the largest dimension to ensure that the matrix can</span>
<span class="sd">        be converted to a skew-symmetric matrix. The resulting matrix is cropped to the original</span>
<span class="sd">        dimension.</span>

<span class="sd">        Args:</span>
<span class="sd">            weight_shape (tuple): The shape of the weight matrix.</span>
<span class="sd">            niters (int): Number of iterations for the series expansion approximation of the</span>
<span class="sd">                matrix exponential. Default is 7.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weight_shape</span> <span class="o">=</span> <span class="n">weight_shape</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_dim</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">weight_shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">:])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">niters</span> <span class="o">=</span> <span class="n">niters</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">BatchedExponentialOrthogonalization</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">w</span><span class="p">):</span>
        <span class="c1"># fill w with zero to have a square matrix over the last two dimensions</span>
        <span class="c1"># if ((self.max_dim - w.shape[-1]) != 0) and ((self.max_dim - w.shape[-2]) != 0):</span>
        <span class="n">w</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span>
            <span class="n">w</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_dim</span> <span class="o">-</span> <span class="n">w</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="mi">0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_dim</span> <span class="o">-</span> <span class="n">w</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">])</span>
        <span class="p">)</span>
        <span class="c1"># makes w skew symmetric</span>
        <span class="n">w</span> <span class="o">=</span> <span class="p">(</span><span class="n">w</span> <span class="o">-</span> <span class="n">w</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">))</span> <span class="o">/</span> <span class="mi">2</span>
        <span class="n">acc</span> <span class="o">=</span> <span class="n">w</span>
        <span class="n">res</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">acc</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">],</span> <span class="n">acc</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="n">w</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="o">+</span> <span class="n">acc</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">niters</span><span class="p">):</span>
            <span class="n">acc</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s2">&quot;...ij,...jk-&gt;...ik&quot;</span><span class="p">,</span> <span class="n">acc</span><span class="p">,</span> <span class="n">w</span><span class="p">)</span> <span class="o">/</span> <span class="n">i</span>
            <span class="n">res</span> <span class="o">=</span> <span class="n">res</span> <span class="o">+</span> <span class="n">acc</span>
        <span class="c1"># if transpose:</span>
        <span class="c1">#     res = res.transpose(-1, -2)</span>
        <span class="n">res</span> <span class="o">=</span> <span class="n">res</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight_shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">],</span> <span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight_shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]]</span>
        <span class="k">return</span> <span class="n">res</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">right_inverse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">w</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">w</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="orthogonium.reparametrizers.BatchedExponentialOrthogonalization.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">weight_shape</span><span class="p">,</span> <span class="n">niters</span><span class="o">=</span><span class="mi">7</span><span class="p">)</span></code>

<a href="#orthogonium.reparametrizers.BatchedExponentialOrthogonalization.__init__" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Initialize the BatchedExponentialOrthogonalization module.</p>
<p>This module orthogonalizes a weight matrix using the exponential map of a skew-symmetric
matrix. By converting the matrix into a skew-symmetric form and applying the matrix
exponential, it produces an orthogonal matrix. This approach is particularly useful
in contexts where smooth transitions between matrices are required.</p>
<p>Non-square matrices are padded to the largest dimension to ensure that the matrix can
be converted to a skew-symmetric matrix. The resulting matrix is cropped to the original
dimension.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>weight_shape</code>
            </td>
            <td>
                  <code>tuple</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The shape of the weight matrix.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>niters</code>
            </td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of iterations for the series expansion approximation of the
matrix exponential. Default is 7.</p>
              </div>
            </td>
            <td>
                  <code>7</code>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>orthogonium\reparametrizers.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">weight_shape</span><span class="p">,</span> <span class="n">niters</span><span class="o">=</span><span class="mi">7</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Initialize the BatchedExponentialOrthogonalization module.</span>

<span class="sd">    This module orthogonalizes a weight matrix using the exponential map of a skew-symmetric</span>
<span class="sd">    matrix. By converting the matrix into a skew-symmetric form and applying the matrix</span>
<span class="sd">    exponential, it produces an orthogonal matrix. This approach is particularly useful</span>
<span class="sd">    in contexts where smooth transitions between matrices are required.</span>

<span class="sd">    Non-square matrices are padded to the largest dimension to ensure that the matrix can</span>
<span class="sd">    be converted to a skew-symmetric matrix. The resulting matrix is cropped to the original</span>
<span class="sd">    dimension.</span>

<span class="sd">    Args:</span>
<span class="sd">        weight_shape (tuple): The shape of the weight matrix.</span>
<span class="sd">        niters (int): Number of iterations for the series expansion approximation of the</span>
<span class="sd">            matrix exponential. Default is 7.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">weight_shape</span> <span class="o">=</span> <span class="n">weight_shape</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">max_dim</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">weight_shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">:])</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">niters</span> <span class="o">=</span> <span class="n">niters</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">BatchedExponentialOrthogonalization</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="orthogonium.reparametrizers.BatchedIdentity" class="doc doc-heading">
            <code>BatchedIdentity</code>


<a href="#orthogonium.reparametrizers.BatchedIdentity" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="torch.nn.Module">Module</span></code></p>







              <details class="quote">
                <summary>Source code in <code>orthogonium\reparametrizers.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">BatchedIdentity</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">weight_shape</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Class representing a batched identity matrix with a specific weight shape. The</span>
<span class="sd">        matrix is initialized based on the provided shape of the weights. It is a</span>
<span class="sd">        convenient utility for applications where identity-like operations are</span>
<span class="sd">        required in a batched manner.</span>

<span class="sd">        Attributes:</span>
<span class="sd">            weight_shape (Tuple[int, int]): A tuple representing the shape of the</span>
<span class="sd">            weight matrix for each batch. (unused)</span>

<span class="sd">        Args:</span>
<span class="sd">            weight_shape: A tuple specifying the shape of the individual weight matrix.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">BatchedIdentity</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">w</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">w</span>

    <span class="k">def</span> <span class="nf">right_inverse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">w</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">w</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="orthogonium.reparametrizers.BatchedIdentity.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">weight_shape</span><span class="p">)</span></code>

<a href="#orthogonium.reparametrizers.BatchedIdentity.__init__" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Class representing a batched identity matrix with a specific weight shape. The
matrix is initialized based on the provided shape of the weights. It is a
convenient utility for applications where identity-like operations are
required in a batched manner.</p>


<p><span class="doc-section-title">Attributes:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code><span title="orthogonium.reparametrizers.BatchedIdentity.__init__.weight_shape">weight_shape</span></code></td>
            <td>
                  <code><span title="typing.Tuple">Tuple</span>[int, int]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A tuple representing the shape of the</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>weight_shape</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A tuple specifying the shape of the individual weight matrix.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>orthogonium\reparametrizers.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">weight_shape</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Class representing a batched identity matrix with a specific weight shape. The</span>
<span class="sd">    matrix is initialized based on the provided shape of the weights. It is a</span>
<span class="sd">    convenient utility for applications where identity-like operations are</span>
<span class="sd">    required in a batched manner.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        weight_shape (Tuple[int, int]): A tuple representing the shape of the</span>
<span class="sd">        weight matrix for each batch. (unused)</span>

<span class="sd">    Args:</span>
<span class="sd">        weight_shape: A tuple specifying the shape of the individual weight matrix.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">BatchedIdentity</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="orthogonium.reparametrizers.BatchedPowerIteration" class="doc doc-heading">
            <code>BatchedPowerIteration</code>


<a href="#orthogonium.reparametrizers.BatchedPowerIteration" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="torch.nn.Module">Module</span></code></p>







              <details class="quote">
                <summary>Source code in <code>orthogonium\reparametrizers.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span>
<span class="normal">74</span>
<span class="normal">75</span>
<span class="normal">76</span>
<span class="normal">77</span>
<span class="normal">78</span>
<span class="normal">79</span>
<span class="normal">80</span>
<span class="normal">81</span>
<span class="normal">82</span>
<span class="normal">83</span>
<span class="normal">84</span>
<span class="normal">85</span>
<span class="normal">86</span>
<span class="normal">87</span>
<span class="normal">88</span>
<span class="normal">89</span>
<span class="normal">90</span>
<span class="normal">91</span>
<span class="normal">92</span>
<span class="normal">93</span>
<span class="normal">94</span>
<span class="normal">95</span>
<span class="normal">96</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">BatchedPowerIteration</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">weight_shape</span><span class="p">,</span> <span class="n">power_it_niter</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-12</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        BatchedPowerIteration is a class that performs spectral normalization on weights</span>
<span class="sd">        using the power iteration method in a batched manner. It initializes singular</span>
<span class="sd">        vectors &#39;u&#39; and &#39;v&#39;, which are used to approximate the largest singular value</span>
<span class="sd">        of the associated weight matrix during training. The L2 normalization is applied</span>
<span class="sd">        to stabilize these singular vector parameters.</span>

<span class="sd">        Attributes:</span>
<span class="sd">            weight_shape: tuple</span>
<span class="sd">                Shape of the weight tensor. Normalization is applied to the last two dimensions.</span>
<span class="sd">            power_it_niter: int</span>
<span class="sd">                Number of iterations to perform for the power iteration method.</span>
<span class="sd">            eps: float</span>
<span class="sd">                A small constant to ensure numerical stability during calculations. Used in the power iteration</span>
<span class="sd">                method to avoid dividing by zero.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">BatchedPowerIteration</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weight_shape</span> <span class="o">=</span> <span class="n">weight_shape</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">power_it_niter</span> <span class="o">=</span> <span class="n">power_it_niter</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eps</span> <span class="o">=</span> <span class="n">eps</span>
        <span class="c1"># init u</span>
        <span class="c1"># u will be weight_shape[:-2] + (weight_shape[:-2], 1)</span>
        <span class="c1"># v will be weight_shape[:-2] + (weight_shape[:-1], 1,)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">u</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="o">*</span><span class="n">weight_shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">2</span><span class="p">],</span> <span class="n">weight_shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">],</span> <span class="mi">1</span><span class="p">)),</span>
            <span class="n">requires_grad</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">v</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="o">*</span><span class="n">weight_shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">2</span><span class="p">],</span> <span class="n">weight_shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="mi">1</span><span class="p">)),</span>
            <span class="n">requires_grad</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">parametrize</span><span class="o">.</span><span class="n">register_parametrization</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;u&quot;</span><span class="p">,</span> <span class="n">L2Normalize</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">u</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">))</span>
        <span class="p">)</span>
        <span class="n">parametrize</span><span class="o">.</span><span class="n">register_parametrization</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;v&quot;</span><span class="p">,</span> <span class="n">L2Normalize</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">v</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">))</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">init_u</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">n_iters</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">return_uv</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_iters</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">v</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">)</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">u</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">u</span> <span class="o">=</span> <span class="n">X</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">v</span>
        <span class="c1"># stop gradient on u and v</span>
        <span class="n">u</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">u</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
        <span class="n">v</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">v</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
        <span class="c1"># but keep gradient on s</span>
        <span class="n">s</span> <span class="o">=</span> <span class="n">u</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">)</span> <span class="o">@</span> <span class="n">X</span> <span class="o">@</span> <span class="n">v</span>
        <span class="k">return</span> <span class="n">X</span> <span class="o">/</span> <span class="p">(</span><span class="n">s</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">eps</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">right_inverse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">normalized_kernel</span><span class="p">):</span>
        <span class="c1"># we assume that the kernel is normalized</span>
        <span class="k">return</span> <span class="n">normalized_kernel</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">u</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="orthogonium.reparametrizers.BatchedPowerIteration.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">weight_shape</span><span class="p">,</span> <span class="n">power_it_niter</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-12</span><span class="p">)</span></code>

<a href="#orthogonium.reparametrizers.BatchedPowerIteration.__init__" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>BatchedPowerIteration is a class that performs spectral normalization on weights
using the power iteration method in a batched manner. It initializes singular
vectors 'u' and 'v', which are used to approximate the largest singular value
of the associated weight matrix during training. The L2 normalization is applied
to stabilize these singular vector parameters.</p>


<p><span class="doc-section-title">Attributes:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code><span title="orthogonium.reparametrizers.BatchedPowerIteration.__init__.weight_shape">weight_shape</span></code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>tuple
Shape of the weight tensor. Normalization is applied to the last two dimensions.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="orthogonium.reparametrizers.BatchedPowerIteration.__init__.power_it_niter">power_it_niter</span></code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>int
Number of iterations to perform for the power iteration method.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="orthogonium.reparametrizers.BatchedPowerIteration.__init__.eps">eps</span></code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>float
A small constant to ensure numerical stability during calculations. Used in the power iteration
method to avoid dividing by zero.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>orthogonium\reparametrizers.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span>
<span class="normal">74</span>
<span class="normal">75</span>
<span class="normal">76</span>
<span class="normal">77</span>
<span class="normal">78</span>
<span class="normal">79</span>
<span class="normal">80</span>
<span class="normal">81</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">weight_shape</span><span class="p">,</span> <span class="n">power_it_niter</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-12</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    BatchedPowerIteration is a class that performs spectral normalization on weights</span>
<span class="sd">    using the power iteration method in a batched manner. It initializes singular</span>
<span class="sd">    vectors &#39;u&#39; and &#39;v&#39;, which are used to approximate the largest singular value</span>
<span class="sd">    of the associated weight matrix during training. The L2 normalization is applied</span>
<span class="sd">    to stabilize these singular vector parameters.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        weight_shape: tuple</span>
<span class="sd">            Shape of the weight tensor. Normalization is applied to the last two dimensions.</span>
<span class="sd">        power_it_niter: int</span>
<span class="sd">            Number of iterations to perform for the power iteration method.</span>
<span class="sd">        eps: float</span>
<span class="sd">            A small constant to ensure numerical stability during calculations. Used in the power iteration</span>
<span class="sd">            method to avoid dividing by zero.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">BatchedPowerIteration</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">weight_shape</span> <span class="o">=</span> <span class="n">weight_shape</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">power_it_niter</span> <span class="o">=</span> <span class="n">power_it_niter</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">eps</span> <span class="o">=</span> <span class="n">eps</span>
    <span class="c1"># init u</span>
    <span class="c1"># u will be weight_shape[:-2] + (weight_shape[:-2], 1)</span>
    <span class="c1"># v will be weight_shape[:-2] + (weight_shape[:-1], 1,)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">u</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="o">*</span><span class="n">weight_shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">2</span><span class="p">],</span> <span class="n">weight_shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">],</span> <span class="mi">1</span><span class="p">)),</span>
        <span class="n">requires_grad</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">v</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="o">*</span><span class="n">weight_shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">2</span><span class="p">],</span> <span class="n">weight_shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="mi">1</span><span class="p">)),</span>
        <span class="n">requires_grad</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">parametrize</span><span class="o">.</span><span class="n">register_parametrization</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;u&quot;</span><span class="p">,</span> <span class="n">L2Normalize</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">u</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">))</span>
    <span class="p">)</span>
    <span class="n">parametrize</span><span class="o">.</span><span class="n">register_parametrization</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;v&quot;</span><span class="p">,</span> <span class="n">L2Normalize</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">v</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">))</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="orthogonium.reparametrizers.BatchedQROrthogonalization" class="doc doc-heading">
            <code>BatchedQROrthogonalization</code>


<a href="#orthogonium.reparametrizers.BatchedQROrthogonalization" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="torch.nn.Module">Module</span></code></p>







              <details class="quote">
                <summary>Source code in <code>orthogonium\reparametrizers.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span>
<span class="normal">351</span>
<span class="normal">352</span>
<span class="normal">353</span>
<span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span>
<span class="normal">360</span>
<span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span>
<span class="normal">366</span>
<span class="normal">367</span>
<span class="normal">368</span>
<span class="normal">369</span>
<span class="normal">370</span>
<span class="normal">371</span>
<span class="normal">372</span>
<span class="normal">373</span>
<span class="normal">374</span>
<span class="normal">375</span>
<span class="normal">376</span>
<span class="normal">377</span>
<span class="normal">378</span>
<span class="normal">379</span>
<span class="normal">380</span>
<span class="normal">381</span>
<span class="normal">382</span>
<span class="normal">383</span>
<span class="normal">384</span>
<span class="normal">385</span>
<span class="normal">386</span>
<span class="normal">387</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">BatchedQROrthogonalization</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">weight_shape</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initialize the BatchedQROrthogonalization module.</span>

<span class="sd">        This module uses QR decomposition to orthogonalize a weight matrix in a batched manner.</span>
<span class="sd">        It computes the orthogonal component (`Q`) from the decomposition, ensuring that the</span>
<span class="sd">        output satisfies orthogonality constraints.</span>

<span class="sd">        Args:</span>
<span class="sd">            weight_shape (tuple): The shape of the weight matrix to be orthogonalized.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">BatchedQROrthogonalization</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">w</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Perform QR decomposition to compute the orthogonalized weight matrix.</span>

<span class="sd">        The QR decomposition splits the input matrix into an orthogonal matrix (`Q`) and</span>
<span class="sd">        an upper triangular matrix (`R`). This module returns the orthogonal component.</span>

<span class="sd">        Args:</span>
<span class="sd">            w (torch.Tensor): The weight matrix to be orthogonalized.</span>

<span class="sd">        Returns:</span>
<span class="sd">            torch.Tensor: The orthogonalized weight matrix (`Q` from the QR decomposition).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">transpose</span> <span class="o">=</span> <span class="n">w</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">w</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">transpose</span><span class="p">:</span>
            <span class="n">w</span> <span class="o">=</span> <span class="n">w</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">q</span><span class="p">,</span> <span class="n">r</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">qr</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;reduced&quot;</span><span class="p">)</span>
        <span class="c1"># compute the sign of the diagonal of d</span>
        <span class="n">diag_sign</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">diagonal</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="n">dim1</span><span class="o">=-</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim2</span><span class="o">=-</span><span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span>
        <span class="c1"># multiply the sign with the diagonal of r</span>
        <span class="n">q</span> <span class="o">=</span> <span class="n">q</span> <span class="o">*</span> <span class="n">diag_sign</span>
        <span class="k">if</span> <span class="n">transpose</span><span class="p">:</span>
            <span class="n">q</span> <span class="o">=</span> <span class="n">q</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">q</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">right_inverse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">w</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">w</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="orthogonium.reparametrizers.BatchedQROrthogonalization.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">weight_shape</span><span class="p">)</span></code>

<a href="#orthogonium.reparametrizers.BatchedQROrthogonalization.__init__" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Initialize the BatchedQROrthogonalization module.</p>
<p>This module uses QR decomposition to orthogonalize a weight matrix in a batched manner.
It computes the orthogonal component (<code>Q</code>) from the decomposition, ensuring that the
output satisfies orthogonality constraints.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>weight_shape</code>
            </td>
            <td>
                  <code>tuple</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The shape of the weight matrix to be orthogonalized.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>orthogonium\reparametrizers.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span>
<span class="normal">351</span>
<span class="normal">352</span>
<span class="normal">353</span>
<span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">weight_shape</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Initialize the BatchedQROrthogonalization module.</span>

<span class="sd">    This module uses QR decomposition to orthogonalize a weight matrix in a batched manner.</span>
<span class="sd">    It computes the orthogonal component (`Q`) from the decomposition, ensuring that the</span>
<span class="sd">    output satisfies orthogonality constraints.</span>

<span class="sd">    Args:</span>
<span class="sd">        weight_shape (tuple): The shape of the weight matrix to be orthogonalized.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">BatchedQROrthogonalization</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="orthogonium.reparametrizers.BatchedQROrthogonalization.forward" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">forward</span><span class="p">(</span><span class="n">w</span><span class="p">)</span></code>

<a href="#orthogonium.reparametrizers.BatchedQROrthogonalization.forward" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Perform QR decomposition to compute the orthogonalized weight matrix.</p>
<p>The QR decomposition splits the input matrix into an orthogonal matrix (<code>Q</code>) and
an upper triangular matrix (<code>R</code>). This module returns the orthogonal component.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>w</code>
            </td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The weight matrix to be orthogonalized.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>torch.Tensor: The orthogonalized weight matrix (<code>Q</code> from the QR decomposition).</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>orthogonium\reparametrizers.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span>
<span class="normal">366</span>
<span class="normal">367</span>
<span class="normal">368</span>
<span class="normal">369</span>
<span class="normal">370</span>
<span class="normal">371</span>
<span class="normal">372</span>
<span class="normal">373</span>
<span class="normal">374</span>
<span class="normal">375</span>
<span class="normal">376</span>
<span class="normal">377</span>
<span class="normal">378</span>
<span class="normal">379</span>
<span class="normal">380</span>
<span class="normal">381</span>
<span class="normal">382</span>
<span class="normal">383</span>
<span class="normal">384</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">w</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Perform QR decomposition to compute the orthogonalized weight matrix.</span>

<span class="sd">    The QR decomposition splits the input matrix into an orthogonal matrix (`Q`) and</span>
<span class="sd">    an upper triangular matrix (`R`). This module returns the orthogonal component.</span>

<span class="sd">    Args:</span>
<span class="sd">        w (torch.Tensor): The weight matrix to be orthogonalized.</span>

<span class="sd">    Returns:</span>
<span class="sd">        torch.Tensor: The orthogonalized weight matrix (`Q` from the QR decomposition).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">transpose</span> <span class="o">=</span> <span class="n">w</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">w</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">transpose</span><span class="p">:</span>
        <span class="n">w</span> <span class="o">=</span> <span class="n">w</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">q</span><span class="p">,</span> <span class="n">r</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">qr</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;reduced&quot;</span><span class="p">)</span>
    <span class="c1"># compute the sign of the diagonal of d</span>
    <span class="n">diag_sign</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">diagonal</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="n">dim1</span><span class="o">=-</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim2</span><span class="o">=-</span><span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span>
    <span class="c1"># multiply the sign with the diagonal of r</span>
    <span class="n">q</span> <span class="o">=</span> <span class="n">q</span> <span class="o">*</span> <span class="n">diag_sign</span>
    <span class="k">if</span> <span class="n">transpose</span><span class="p">:</span>
        <span class="n">q</span> <span class="o">=</span> <span class="n">q</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">q</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="orthogonium.reparametrizers.L2Normalize" class="doc doc-heading">
            <code>L2Normalize</code>


<a href="#orthogonium.reparametrizers.L2Normalize" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="torch.nn.Module">Module</span></code></p>







              <details class="quote">
                <summary>Source code in <code>orthogonium\reparametrizers.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">L2Normalize</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        A class that performs L2 normalization for the given input tensor.</span>

<span class="sd">        L2 normalization is a process that normalizes the input over a specified</span>
<span class="sd">        dimension such that the sum of squares of the elements along that</span>
<span class="sd">        dimension equals 1. It ensures that the resulting tensor has a unit norm.</span>
<span class="sd">        This operation is widely used in machine learning and deep learning</span>
<span class="sd">        applications to standardize feature representations.</span>

<span class="sd">        Attributes:</span>
<span class="sd">            dim (Optional[int]): The specific dimension along which normalization</span>
<span class="sd">                is performed. If None, normalization is done over all dimensions.</span>
<span class="sd">            dtype (Any): The data type of the tensor to be normalized.</span>

<span class="sd">        Parameters:</span>
<span class="sd">            dtype: The data type of the tensor to be normalized.</span>
<span class="sd">            dim: An optional integer specifying the dimension along which to</span>
<span class="sd">                normalize. If not provided, the input will be normalized globally</span>
<span class="sd">                across all dimensions.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">L2Normalize</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dim</span> <span class="o">=</span> <span class="n">dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">dtype</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">x</span> <span class="o">/</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span> <span class="o">+</span> <span class="mf">1e-8</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">right_inverse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">x</span> <span class="o">/</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span> <span class="o">+</span> <span class="mf">1e-8</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="orthogonium.reparametrizers.L2Normalize.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">dtype</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

<a href="#orthogonium.reparametrizers.L2Normalize.__init__" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>A class that performs L2 normalization for the given input tensor.</p>
<p>L2 normalization is a process that normalizes the input over a specified
dimension such that the sum of squares of the elements along that
dimension equals 1. It ensures that the resulting tensor has a unit norm.
This operation is widely used in machine learning and deep learning
applications to standardize feature representations.</p>


<p><span class="doc-section-title">Attributes:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code><span title="orthogonium.reparametrizers.L2Normalize.__init__.dim">dim</span></code></td>
            <td>
                  <code>Optional[int]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The specific dimension along which normalization
is performed. If None, normalization is done over all dimensions.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="orthogonium.reparametrizers.L2Normalize.__init__.dtype">dtype</span></code></td>
            <td>
                  <code>Any</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The data type of the tensor to be normalized.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>dtype</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The data type of the tensor to be normalized.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>dim</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>An optional integer specifying the dimension along which to
normalize. If not provided, the input will be normalized globally
across all dimensions.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>orthogonium\reparametrizers.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A class that performs L2 normalization for the given input tensor.</span>

<span class="sd">    L2 normalization is a process that normalizes the input over a specified</span>
<span class="sd">    dimension such that the sum of squares of the elements along that</span>
<span class="sd">    dimension equals 1. It ensures that the resulting tensor has a unit norm.</span>
<span class="sd">    This operation is widely used in machine learning and deep learning</span>
<span class="sd">    applications to standardize feature representations.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        dim (Optional[int]): The specific dimension along which normalization</span>
<span class="sd">            is performed. If None, normalization is done over all dimensions.</span>
<span class="sd">        dtype (Any): The data type of the tensor to be normalized.</span>

<span class="sd">    Parameters:</span>
<span class="sd">        dtype: The data type of the tensor to be normalized.</span>
<span class="sd">        dim: An optional integer specifying the dimension along which to</span>
<span class="sd">            normalize. If not provided, the input will be normalized globally</span>
<span class="sd">            across all dimensions.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">L2Normalize</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dim</span> <span class="o">=</span> <span class="n">dim</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">dtype</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="orthogonium.reparametrizers.OrthoParams" class="doc doc-heading">
            <code>OrthoParams</code>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-dataclass"><code>dataclass</code></small>
  </span>

<a href="#orthogonium.reparametrizers.OrthoParams" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents ">


        <p>Represents the parameters and configurations used for orthogonalization
and spectral normalization.</p>
<p>This class encapsulates the necessary modules and settings required
for performing spectral normalization and orthogonalization of tensors
in a parameterized way. It accommodates various implementations of
normalizers and orthogonalization techniques to provide flexibility
in their application. This way we can easily switch between different
normalization techniques inside our layer despite that each normalization
have different parameters.</p>


<p><span class="doc-section-title">Attributes:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code><span title="orthogonium.reparametrizers.OrthoParams.spectral_normalizer">spectral_normalizer</span></code></td>
            <td>
                  <code><span title="typing.Callable">Callable</span>[<span title="typing.Tuple">Tuple</span>[int, ...], <span title="torch.nn.Module">Module</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A callable
that produces a module for spectral normalization. Default is
configured to use BatchedPowerIteration with specific parameters.
This callable can be provided either as a <code>functool.partial</code> or as a
<code>orthogonium.ClassParam</code>. It will recieve the shape of the weight tensor as its
argument.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="orthogonium.reparametrizers.OrthoParams.orthogonalizer">orthogonalizer</span></code></td>
            <td>
                  <code><span title="typing.Callable">Callable</span>[<span title="typing.Tuple">Tuple</span>[int, ...], <span title="torch.nn.Module">Module</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A callable
that produces a module for orthogonalization. Default is
configured to use BatchedBjorckOrthogonalization with specific
parameters. This callable can be provided either as a <code>functool.partial</code> or as a
<code>orthogonium.ClassParam</code>. It will recieve the shape of the weight tensor as its argument.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>






              <details class="quote">
                <summary>Source code in <code>orthogonium\reparametrizers.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">390</span>
<span class="normal">391</span>
<span class="normal">392</span>
<span class="normal">393</span>
<span class="normal">394</span>
<span class="normal">395</span>
<span class="normal">396</span>
<span class="normal">397</span>
<span class="normal">398</span>
<span class="normal">399</span>
<span class="normal">400</span>
<span class="normal">401</span>
<span class="normal">402</span>
<span class="normal">403</span>
<span class="normal">404</span>
<span class="normal">405</span>
<span class="normal">406</span>
<span class="normal">407</span>
<span class="normal">408</span>
<span class="normal">409</span>
<span class="normal">410</span>
<span class="normal">411</span>
<span class="normal">412</span>
<span class="normal">413</span>
<span class="normal">414</span>
<span class="normal">415</span>
<span class="normal">416</span>
<span class="normal">417</span>
<span class="normal">418</span>
<span class="normal">419</span>
<span class="normal">420</span>
<span class="normal">421</span>
<span class="normal">422</span>
<span class="normal">423</span>
<span class="normal">424</span>
<span class="normal">425</span>
<span class="normal">426</span>
<span class="normal">427</span>
<span class="normal">428</span>
<span class="normal">429</span>
<span class="normal">430</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@dataclass</span>
<span class="k">class</span> <span class="nc">OrthoParams</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Represents the parameters and configurations used for orthogonalization</span>
<span class="sd">    and spectral normalization.</span>

<span class="sd">    This class encapsulates the necessary modules and settings required</span>
<span class="sd">    for performing spectral normalization and orthogonalization of tensors</span>
<span class="sd">    in a parameterized way. It accommodates various implementations of</span>
<span class="sd">    normalizers and orthogonalization techniques to provide flexibility</span>
<span class="sd">    in their application. This way we can easily switch between different</span>
<span class="sd">    normalization techniques inside our layer despite that each normalization</span>
<span class="sd">    have different parameters.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        spectral_normalizer (Callable[Tuple[int, ...], nn.Module]): A callable</span>
<span class="sd">            that produces a module for spectral normalization. Default is</span>
<span class="sd">            configured to use BatchedPowerIteration with specific parameters.</span>
<span class="sd">            This callable can be provided either as a `functool.partial` or as a</span>
<span class="sd">            `orthogonium.ClassParam`. It will recieve the shape of the weight tensor as its</span>
<span class="sd">            argument.</span>
<span class="sd">        orthogonalizer (Callable[Tuple[int, ...], nn.Module]): A callable</span>
<span class="sd">            that produces a module for orthogonalization. Default is</span>
<span class="sd">            configured to use BatchedBjorckOrthogonalization with specific</span>
<span class="sd">            parameters. This callable can be provided either as a `functool.partial` or as a</span>
<span class="sd">            `orthogonium.ClassParam`. It will recieve the shape of the weight tensor as its argument.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># spectral_normalizer: Callable[Tuple[int, ...], nn.Module] = BatchedIdentity</span>
    <span class="n">spectral_normalizer</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="o">...</span><span class="p">],</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">]</span> <span class="o">=</span> <span class="n">ClassParam</span><span class="p">(</span>  <span class="c1"># type: ignore</span>
        <span class="n">BatchedPowerIteration</span><span class="p">,</span> <span class="n">power_it_niter</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-6</span>
    <span class="p">)</span>
    <span class="n">orthogonalizer</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="o">...</span><span class="p">],</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">]</span> <span class="o">=</span> <span class="n">ClassParam</span><span class="p">(</span>  <span class="c1"># type: ignore</span>
        <span class="n">BatchedBjorckOrthogonalization</span><span class="p">,</span>
        <span class="n">beta</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
        <span class="n">niters</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span>
        <span class="n">pass_through</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="c1"># ClassParam(BatchedExponentialOrthogonalization, niters=12)</span>
        <span class="c1"># BatchedCholeskyOrthogonalization,</span>
        <span class="c1"># BatchedQROrthogonalization,</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">











  </div>

    </div>

</div>




  </div>

    </div>

</div>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../..", "features": [], "search": "../../assets/javascripts/workers/search.6ce7567c.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../assets/javascripts/bundle.88dd0f4e.min.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
        <script src="../../js/custom.js"></script>
      
    
  </body>
</html>